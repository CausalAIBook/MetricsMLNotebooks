{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.024906,
          "end_time": "2021-07-23T16:17:55.704014",
          "exception": false,
          "start_time": "2021-07-23T16:17:55.679108",
          "status": "completed"
        },
        "tags": [],
        "id": "a19sSgshu-SA"
      },
      "source": [
        "# A Case Study: The Effect of Gun Ownership on Gun-Homicide Rates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.024533,
          "end_time": "2021-07-23T16:17:55.753444",
          "exception": false,
          "start_time": "2021-07-23T16:17:55.728911",
          "status": "completed"
        },
        "tags": [],
        "id": "R4ZopCRVu-SA"
      },
      "source": [
        "We consider the problem of estimating the effect of gun\n",
        "ownership on the homicide rate. For this purpose, we estimate the following partially\n",
        "linear model\n",
        "\n",
        "$$\n",
        " Y_{j,t} = \\beta D_{j,(t-1)} + g(Z_{j,t}) + \\epsilon_{j,t}.\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.024711,
          "end_time": "2021-07-23T16:17:55.803109",
          "exception": false,
          "start_time": "2021-07-23T16:17:55.778398",
          "status": "completed"
        },
        "tags": [],
        "id": "ubu-QI2Ju-SB"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.025115,
          "end_time": "2021-07-23T16:17:55.854426",
          "exception": false,
          "start_time": "2021-07-23T16:17:55.829311",
          "status": "completed"
        },
        "tags": [],
        "id": "fV3y0eiCu-SB"
      },
      "source": [
        "$Y_{j,t}$ is the log homicide rate in county $j$ at time $t$, $D_{j, t-1}$ is the log fraction of suicides committed with a firearm in county $j$ at time $t-1$, which we use as a proxy for gun ownership,  and  $Z_{j,t}$ is a set of demographic and economic characteristics of county $j$ at time $t$. The parameter $\\beta$ is the effect of gun ownership on homicide rates, controlling for county-level demographic and economic characteristics.\n",
        "\n",
        "The sample covers 195 large United States counties between the years 1980 through 1999, giving us 3900 observations."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import relevant packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV, LinearRegression, Ridge, Lasso, LogisticRegressionCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "import patsy\n",
        "import warnings\n",
        "from sklearn.base import BaseEstimator, clone\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "np.random.seed(1234)"
      ],
      "metadata": {
        "id": "x4283h0kwo_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = \"https://raw.githubusercontent.com/CausalAIBook/MetricsMLNotebooks/main/data/gun_clean.csv\"\n",
        "data = pd.read_csv(file)\n",
        "data.shape"
      ],
      "metadata": {
        "id": "g6JCZCdqvj1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.025977,
          "end_time": "2021-07-23T16:17:57.064860",
          "exception": false,
          "start_time": "2021-07-23T16:17:57.038883",
          "status": "completed"
        },
        "tags": [],
        "id": "TkxefAQ7u-SD"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.024998,
          "end_time": "2021-07-23T16:17:57.115009",
          "exception": false,
          "start_time": "2021-07-23T16:17:57.090011",
          "status": "completed"
        },
        "tags": [],
        "id": "FR0sUlnYu-SD"
      },
      "source": [
        "To account for heterogeneity across counties and time trends in  all variables, we remove from them county-specific and time-specific effects in the following preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-23T16:17:57.221326Z",
          "iopub.status.busy": "2021-07-23T16:17:57.169803Z",
          "iopub.status.idle": "2021-07-23T16:18:23.043752Z",
          "shell.execute_reply": "2021-07-23T16:18:23.042830Z"
        },
        "papermill": {
          "duration": 25.903532,
          "end_time": "2021-07-23T16:18:23.043902",
          "exception": false,
          "start_time": "2021-07-23T16:17:57.140370",
          "status": "completed"
        },
        "tags": [],
        "id": "1tvTY-Tbu-SE"
      },
      "outputs": [],
      "source": [
        "##################### Find Variable Names from Dataset ######################\n",
        "def varlist(df=None, type=[\"numeric\", \"factor\", \"character\"], pattern=\"\", exclude=None):\n",
        "    vars = []\n",
        "    if any(t in type for t in [\"numeric\", \"factor\", \"character\"]):\n",
        "        if \"numeric\" in type:\n",
        "            vars += df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
        "        if \"factor\" in type:\n",
        "            vars += df.select_dtypes(include=[\"category\"]).columns.tolist()\n",
        "        if \"character\" in type:\n",
        "            vars += df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "    if exclude:\n",
        "        vars = [var for var in vars if var not in exclude]\n",
        "\n",
        "    if pattern:\n",
        "        vars = [var for var in vars if re.search(pattern, var)]\n",
        "\n",
        "    return vars\n",
        "\n",
        "\n",
        "############################# Create Variables ##############################\n",
        "\n",
        "# dummy variables for year and county fixed effects\n",
        "fixed = [col for col in data.columns if \"X_Jfips\" in col]\n",
        "year = varlist(data, pattern=\"X_Tyear\")\n",
        "\n",
        "# census control variables\n",
        "census = []\n",
        "census_var = [\"^AGE\", \"^BN\", \"^BP\", \"^BZ\", \"^ED\", \"^EL\", \"^HI\", \"^HS\", \"^INC\", \"^LF\", \"^LN\", \"^PI\", \"^PO\", \"^PP\", \"^PV\", \"^SPR\", \"^VS\"]\n",
        "\n",
        "for pattern in census_var:\n",
        "    census.extend(varlist(data, pattern=pattern))\n",
        "\n",
        "################################ Variables ##################################\n",
        "# treatment variable\n",
        "d = \"logfssl\"\n",
        "# outcome variable\n",
        "y = \"logghomr\"\n",
        "# other control variables\n",
        "X1 = [\"logrobr\", \"logburg\", \"burg_missing\", \"robrate_missing\"]\n",
        "X2 = [\"newblack\", \"newfhh\", \"newmove\", \"newdens\", \"newmal\"]\n",
        "\n",
        "\n",
        "######################## Partial out Fixed Effects ##########################\n",
        "\n",
        "# new dataset for partialled-out variables\n",
        "rdata = pd.DataFrame(data[\"CountyCode\"])\n",
        "\n",
        "# variables to partial out\n",
        "pvar = [y, d] + X1 + X2 + census\n",
        "\n",
        "# partial out year and county fixed effect from variables in pvar\n",
        "residuals = []\n",
        "for var in pvar:\n",
        "    formula = f\"{var} ~ {' + '.join(year)} + {' + '.join(fixed)}\"\n",
        "    model = sm.OLS.from_formula(formula, data=data)\n",
        "    result = model.fit()\n",
        "    residuals.append(pd.Series(result.resid, name=var))\n",
        "\n",
        "rdata = pd.concat([rdata] + residuals, axis=1)\n",
        "\n",
        "rdata.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.025494,
          "end_time": "2021-07-23T16:18:23.095320",
          "exception": false,
          "start_time": "2021-07-23T16:18:23.069826",
          "status": "completed"
        },
        "tags": [],
        "id": "v5Hlpqn8u-SE"
      },
      "source": [
        "Now, we can construct the treatment variable, the outcome variable and the matrix $Z$ that includes the control variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-23T16:18:23.151589Z",
          "iopub.status.busy": "2021-07-23T16:18:23.150087Z",
          "iopub.status.idle": "2021-07-23T16:18:23.171298Z",
          "shell.execute_reply": "2021-07-23T16:18:23.169940Z"
        },
        "papermill": {
          "duration": 0.050666,
          "end_time": "2021-07-23T16:18:23.171445",
          "exception": false,
          "start_time": "2021-07-23T16:18:23.120779",
          "status": "completed"
        },
        "tags": [],
        "id": "s0AIPBVnu-SE"
      },
      "outputs": [],
      "source": [
        "# Treatment variable\n",
        "D = rdata[d]\n",
        "\n",
        "# Outcome variable\n",
        "Y = rdata[y]\n",
        "\n",
        "# Construct matrix Z\n",
        "Z_cols = X1 + X2 + census\n",
        "Z = rdata[Z_cols]\n",
        "Z.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.025783,
          "end_time": "2021-07-23T16:18:23.223256",
          "exception": false,
          "start_time": "2021-07-23T16:18:23.197473",
          "status": "completed"
        },
        "tags": [],
        "id": "kFqD7_oWu-SF"
      },
      "source": [
        "We have 195 control variables in total. The control variables $Z_{j,t}$ are from the U.S. Census Bureau and  contain demographic and economic characteristics of the counties such as  the age distribution, the income distribution, crime rates, federal spending, home ownership rates, house prices, educational attainment, voting paterns, employment statistics, and migration rates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-23T16:18:23.280530Z",
          "iopub.status.busy": "2021-07-23T16:18:23.279019Z",
          "iopub.status.idle": "2021-07-23T16:18:23.293787Z",
          "shell.execute_reply": "2021-07-23T16:18:23.292611Z"
        },
        "papermill": {
          "duration": 0.044714,
          "end_time": "2021-07-23T16:18:23.293932",
          "exception": false,
          "start_time": "2021-07-23T16:18:23.249218",
          "status": "completed"
        },
        "tags": [],
        "id": "5IpN2bHuu-SF"
      },
      "outputs": [],
      "source": [
        "clu = rdata[\"CountyCode\"]  # for clustering SE\n",
        "time = np.tile(np.arange(20), int(data.shape[0]/20))\n",
        "time = pd.Series(time, name='time')\n",
        "data = pd.concat([Y, D, Z, clu, pd.Series(time)], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.02615,
          "end_time": "2021-07-23T16:18:24.461261",
          "exception": false,
          "start_time": "2021-07-23T16:18:24.435111",
          "status": "completed"
        },
        "tags": [],
        "id": "s7ngh8j2u-SF"
      },
      "source": [
        "## The effect of gun ownership"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.02615,
          "end_time": "2021-07-23T16:18:24.513673",
          "exception": false,
          "start_time": "2021-07-23T16:18:24.487523",
          "status": "completed"
        },
        "tags": [],
        "id": "d-qK9imxu-SF"
      },
      "source": [
        "### OLS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.027888,
          "end_time": "2021-07-23T16:18:24.568278",
          "exception": false,
          "start_time": "2021-07-23T16:18:24.540390",
          "status": "completed"
        },
        "tags": [],
        "id": "tiBCuqUdu-SG"
      },
      "source": [
        "After preprocessing the data, as a baseline model, we first look at simple regression of $Y_{j,t}$ on $D_{j,t-1}$ without controls."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ols_model = smf.ols(formula = 'logghomr ~ 1 + logfssl', data = data).fit(cov_type='cluster', cov_kwds={\"groups\": data['CountyCode']})\n",
        "ols_model.summary()"
      ],
      "metadata": {
        "id": "WhHzCj-p9BM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.02777,
          "end_time": "2021-07-23T16:18:24.772317",
          "exception": false,
          "start_time": "2021-07-23T16:18:24.744547",
          "status": "completed"
        },
        "tags": [],
        "id": "8UEWtnP_u-SG"
      },
      "source": [
        "The point estimate is $0.282$ with the confidence interval ranging from 0.155 to 0.41. This\n",
        "suggests that increases in gun ownership rates are related to gun homicide rates - if gun ownership increases by 1% relative\n",
        "to a trend then the predicted gun homicide rate goes up by 0.28%, without controlling for counties' characteristics.\n",
        "\n",
        "Since our goal is to estimate the effect of gun ownership after controlling for a rich set county characteristics, we next include the controls. First, we estimate the model by ols and then by an array of the modern regression methods using the double machine learning approach."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def formula_from_cols(df, y):\n",
        "    return y + ' ~ ' + ' + '.join([col for col in df.columns if not col==y])\n",
        "\n",
        "form = formula_from_cols(data,'logghomr')"
      ],
      "metadata": {
        "id": "EbUezY_N-Aou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ols_model = smf.ols(formula = form, data = data).fit(cov_type='cluster', cov_kwds={\"groups\": data['CountyCode']})\n",
        "ols_model.summary()"
      ],
      "metadata": {
        "id": "Mch--kzm9x1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.043087,
          "end_time": "2021-07-23T16:18:25.122084",
          "exception": false,
          "start_time": "2021-07-23T16:18:25.078997",
          "status": "completed"
        },
        "tags": [],
        "id": "gUCHHG2Mu-SG"
      },
      "source": [
        "After controlling for a rich set of characteristics, the point estimate of gun ownership reduces to $0.19$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.029945,
          "end_time": "2021-07-23T16:18:25.181867",
          "exception": false,
          "start_time": "2021-07-23T16:18:25.151922",
          "status": "completed"
        },
        "tags": [],
        "id": "e7xQ1Vyyu-SG"
      },
      "source": [
        "# DML algorithm\n",
        "\n",
        "Here we perform inference on the predictive coefficient $\\beta$ in our partially linear statistical model,\n",
        "\n",
        "$$\n",
        "Y = D\\beta + g(Z) + \\epsilon, \\quad E (\\epsilon | D, Z) = 0,\n",
        "$$\n",
        "\n",
        "using the **double machine learning** approach.\n",
        "\n",
        "For $\\tilde Y = Y- E(Y|Z)$ and $\\tilde D= D- E(D|Z)$, we can write\n",
        "$$\n",
        "\\tilde Y = \\alpha \\tilde D + \\epsilon, \\quad E (\\epsilon |\\tilde D) =0.\n",
        "$$\n",
        "\n",
        "Using cross-fitting, we employ modern regression methods\n",
        "to build estimators $\\hat \\ell(Z)$ and $\\hat m(Z)$ of $\\ell(Z):=E(Y|Z)$ and $m(Z):=E(D|Z)$ to obtain the estimates of the residualized quantities:\n",
        "\n",
        "$$\n",
        "\\tilde Y_i = Y_i  - \\hat \\ell (Z_i),   \\quad \\tilde D_i = D_i - \\hat m(Z_i), \\quad \\text{ for each } i = 1,\\dots,n.\n",
        "$$\n",
        "\n",
        "Finally, using ordinary least squares of $\\tilde Y_i$ on $\\tilde D_i$, we obtain the\n",
        "estimate of $\\beta$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.029683,
          "end_time": "2021-07-23T16:18:25.241259",
          "exception": false,
          "start_time": "2021-07-23T16:18:25.211576",
          "status": "completed"
        },
        "tags": [],
        "id": "yd_4MobAu-SH"
      },
      "source": [
        "The following algorithm comsumes $Y, D, Z$, and a machine learning method for learning the residuals $\\tilde Y$ and $\\tilde D$, where the residuals are obtained by cross-validation (cross-fitting). Then, it prints the estimated coefficient $\\beta$ and the corresponding standard error from the final OLS regression."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dml(X, D, y, modely, modeld, *, nfolds, classifier=False, time = None, clu = None, cluster = True):\n",
        "    '''\n",
        "    DML for the Partially Linear Model setting with cross-fitting\n",
        "\n",
        "    Input\n",
        "    -----\n",
        "    X: the controls\n",
        "    D: the treatment\n",
        "    y: the outcome\n",
        "    modely: the ML model for predicting the outcome y\n",
        "    modeld: the ML model for predicting the treatment D\n",
        "    nfolds: the number of folds in cross-fitting\n",
        "    classifier: bool, whether the modeld is a classifier or a regressor\n",
        "\n",
        "    time: array of time indices, eg [0,1,...,T-1,0,1,...,T-1,...,0,1,...,T-1]\n",
        "    clu: array of cluster indices, eg [1073, 1073, 1073, ..., 5055, 5055, 5055, 5055]\n",
        "    cluster: bool, whether to use clustered standard errors\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "    point: the point estimate of the treatment effect of D on y\n",
        "    stderr: the standard error of the treatment effect\n",
        "    yhat: the cross-fitted predictions for the outcome y\n",
        "    Dhat: the cross-fitted predictions for the treatment D\n",
        "    resy: the outcome residuals\n",
        "    resD: the treatment residuals\n",
        "    epsilon: the final residual-on-residual OLS regression residual\n",
        "    '''\n",
        "    cv = KFold(n_splits=nfolds, shuffle=True, random_state=123) # shuffled k-folds\n",
        "    yhat = cross_val_predict(modely, X, y, cv=cv, n_jobs=-1) # out-of-fold predictions for y\n",
        "    # out-of-fold predictions for D\n",
        "    # use predict or predict_proba dependent on classifier or regressor for D\n",
        "    if classifier:\n",
        "        Dhat = cross_val_predict(modeld, X, D, cv=cv, method='predict_proba', n_jobs=-1)[:, 1]\n",
        "    else:\n",
        "        Dhat = cross_val_predict(modeld, X, D, cv=cv, n_jobs=-1)\n",
        "    # calculate outcome and treatment residuals\n",
        "    resy = y - yhat\n",
        "    resD = D - Dhat\n",
        "\n",
        "    if cluster:\n",
        "      # final stage ols clustered\n",
        "      dml_data = pd.concat([clu, pd.Series(time), pd.Series(resy, name = 'resy'), pd.Series(resD, name = 'resD')], axis=1)\n",
        "\n",
        "    else:\n",
        "      # final stage ols nonclustered\n",
        "      dml_data = pd.concat([pd.Series(resy, name = 'resy'), pd.Series(resD, name = 'resD')], axis=1)\n",
        "\n",
        "    if cluster:\n",
        "      # clustered standard errors\n",
        "      ols_mod = smf.ols(formula = 'resy ~ 1 + resD', data = dml_data).fit(cov_type='cluster', cov_kwds={\"groups\": dml_data['CountyCode']})\n",
        "\n",
        "    else:\n",
        "      # regular ols\n",
        "      ols_mod = smf.ols(formula = 'resy ~ 1 + resD', data = dml_data).fit()\n",
        "\n",
        "    point = ols_mod.params[1]\n",
        "    stderr = ols_mod.bse[1]\n",
        "    epsilon = ols_mod.resid\n",
        "\n",
        "    return point, stderr, yhat, Dhat, resy, resD, epsilon"
      ],
      "metadata": {
        "id": "sakc09Jv0ggw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summary(point, stderr, yhat, Dhat, resy, resD, epsilon, X, D, y, *, name):\n",
        "    '''\n",
        "    Convenience summary function that takes the results of the DML function\n",
        "    and summarizes several estimation quantities and performance metrics.\n",
        "    '''\n",
        "    return pd.DataFrame({'estimate': point, # point estimate\n",
        "                         'stderr': stderr, # standard error\n",
        "                         'lower': point - 1.96*stderr, # lower end of 95% confidence interval\n",
        "                         'upper': point + 1.96*stderr, # upper end of 95% confidence interval\n",
        "                         'rmse y': np.sqrt(np.mean(resy**2)), # RMSE of model that predicts outcome y\n",
        "                         'rmse D': np.sqrt(np.mean(resD**2)) # RMSE of model that predicts treatment D\n",
        "                         }, index=[name])"
      ],
      "metadata": {
        "id": "r4lz1FbliN3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.031675,
          "end_time": "2021-07-23T16:18:26.151956",
          "exception": false,
          "start_time": "2021-07-23T16:18:26.120281",
          "status": "completed"
        },
        "tags": [],
        "id": "hCWz8jt7u-SI"
      },
      "source": [
        "In the following, we apply the DML approach with the different versions of lasso.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.031799,
          "end_time": "2021-07-23T16:18:26.216020",
          "exception": false,
          "start_time": "2021-07-23T16:18:26.184221",
          "status": "completed"
        },
        "tags": [],
        "id": "TJIgRXpLu-SI"
      },
      "source": [
        "## Lasso"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install multiprocess\n",
        "!git clone https://github.com/maxhuppertz/hdmpy.git"
      ],
      "metadata": {
        "id": "dYLbWkQ5547S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following command to install hdmpy for rigorous lasso:\n",
        "\n",
        "``` !pip install multiprocess ```\n",
        "\n",
        "\n",
        "```!git clone https://github.com/maxhuppertz/hdmpy.git ```"
      ],
      "metadata": {
        "id": "X5foz4zRoVRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hdmpy\n",
        "from sklearn.base import BaseEstimator, clone\n",
        "\n",
        "class RLasso(BaseEstimator):\n",
        "\n",
        "    def __init__(self, *, post=True):\n",
        "        self.post = post\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.rlasso_ = hdmpy.rlasso(X, y, post=self.post)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array(X) @ np.array(self.rlasso_.est['beta']).flatten() + np.array(self.rlasso_.est['intercept'])\n",
        "\n",
        "lasso_model = lambda: RLasso(post=False)"
      ],
      "metadata": {
        "id": "zA7xYTWboQI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DML with RLasso:\n",
        "modely = make_pipeline(StandardScaler(), RLasso(post=False))\n",
        "modeld = make_pipeline(StandardScaler(), RLasso(post=False))\n",
        "\n",
        "# Run DML model with nfolds folds of cross-fitting\n",
        "result_RLasso = dml(Z, D, Y, modely, modeld, nfolds=5, classifier=False, time = time, clu = clu, cluster = True)\n",
        "table_RLasso = summary(*result_RLasso, Z,D, y, name = 'RLasso')\n",
        "table_RLasso"
      ],
      "metadata": {
        "id": "p_fu_zg1Rhru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DML with Post-Lasso:\n",
        "modely = make_pipeline(StandardScaler(), RLasso(post=True))\n",
        "modeld = make_pipeline(StandardScaler(), RLasso(post=True))\n",
        "\n",
        "# Run DML model with nfolds folds of cross-fitting\n",
        "result_post = dml(Z, D, Y, modely, modeld, nfolds=5, classifier=False, time = time, clu = clu, cluster = True)\n",
        "table_post = summary(*result_post, Z,D, y, name = 'Post Lasso')\n",
        "table_post"
      ],
      "metadata": {
        "id": "Dn7kdf3DRiAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now lets do Cross-validated Lasso, Ridge, ENet\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=123) # shuffled k-folds"
      ],
      "metadata": {
        "id": "NmnXjQ5uZ5a1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LassoCV models with n_splits folds of cross-validation\n",
        "modely = make_pipeline(StandardScaler(), LassoCV(cv=cv))\n",
        "modeld = make_pipeline(StandardScaler(), LassoCV(cv=cv))\n",
        "\n",
        "# Run DML model with nfolds folds of cross-fitting\n",
        "result_LassoCV = dml(Z, D, Y, modely, modeld, nfolds=5, classifier=False, time = time, clu = clu, cluster = True)\n",
        "table_LassoCV = summary(*result_LassoCV, Z,D, y, name = 'LassoCV')\n",
        "table_LassoCV"
      ],
      "metadata": {
        "id": "eZf1xNWBoXeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define RidgeCV models with n_splits folds of cross-validation\n",
        "modely = make_pipeline(StandardScaler(), RidgeCV(cv=cv))\n",
        "modeld = make_pipeline(StandardScaler(), RidgeCV(cv=cv))\n",
        "\n",
        "# Run DML model with nfolds folds of cross-fitting\n",
        "result_RidgeCV = dml(Z, D, Y, modely, modeld, nfolds=5, classifier=False, time = time, clu = clu, cluster = True)\n",
        "table_RidgeCV = summary(*result_RidgeCV, Z, D, y, name = 'RidgeCV')\n",
        "table_RidgeCV"
      ],
      "metadata": {
        "id": "AzopGWpJYdcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define ElasticNetCV models with n_splits folds of cross-validation\n",
        "modely = make_pipeline(StandardScaler(), ElasticNetCV(l1_ratio = 0.5, cv=cv))\n",
        "modeld = make_pipeline(StandardScaler(), ElasticNetCV(l1_ratio = 0.5, cv=cv))\n",
        "\n",
        "# Run DML model with nfolds folds of cross-fitting\n",
        "result_ENetCV = dml(Z, D, Y, modely, modeld, nfolds=5, classifier=False, time = time, clu = clu, cluster = True)\n",
        "table_ENetCV = summary(*result_ENetCV, Z,D, y, name = 'ENetCV')\n",
        "table_ENetCV"
      ],
      "metadata": {
        "id": "yOC2nho2oXjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.032997,
          "end_time": "2021-07-23T16:22:49.896173",
          "exception": false,
          "start_time": "2021-07-23T16:22:49.863176",
          "status": "completed"
        },
        "tags": [],
        "id": "cc6xrTBXu-SJ"
      },
      "source": [
        "Here we also compute DML with OLS used as the ML method. Note this produces similar results to what we found in the beginning (FWL Theorem), but slightly different as we conduct cross-fitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-23T16:22:49.967771Z",
          "iopub.status.busy": "2021-07-23T16:22:49.966766Z",
          "iopub.status.idle": "2021-07-23T16:22:56.011257Z",
          "shell.execute_reply": "2021-07-23T16:22:56.010000Z"
        },
        "papermill": {
          "duration": 6.081638,
          "end_time": "2021-07-23T16:22:56.011495",
          "exception": false,
          "start_time": "2021-07-23T16:22:49.929857",
          "status": "completed"
        },
        "tags": [],
        "id": "Rgo6tzTzu-SJ"
      },
      "outputs": [],
      "source": [
        "# DML with OLS:\n",
        "modely = make_pipeline(StandardScaler(), LinearRegression())\n",
        "modeld = make_pipeline(StandardScaler(), LinearRegression())\n",
        "\n",
        "# Run DML model with nfolds folds of cross-fitting\n",
        "result_OLS = dml(Z, D, Y, modely, modeld, nfolds=5, classifier=False, time = time, clu = clu, cluster = True)\n",
        "table_OLS = summary(*result_OLS, Z,D, y, name = 'OLS (DML)')\n",
        "table_OLS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.034198,
          "end_time": "2021-07-23T16:22:56.080477",
          "exception": false,
          "start_time": "2021-07-23T16:22:56.046279",
          "status": "completed"
        },
        "tags": [],
        "id": "uR2S77hXu-SJ"
      },
      "source": [
        "Next, we also apply Random Forest for comparison purposes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.034213,
          "end_time": "2021-07-23T16:22:56.149222",
          "exception": false,
          "start_time": "2021-07-23T16:22:56.115009",
          "status": "completed"
        },
        "tags": [],
        "id": "ybmz9e8du-SJ"
      },
      "source": [
        "### Random Forest\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DML with Random Forests. RFs don't require scaling but we do it for consistency\n",
        "modely = make_pipeline(StandardScaler(), RandomForestRegressor(n_estimators=100, min_samples_leaf=5, random_state=123))\n",
        "modeld = make_pipeline(StandardScaler(), RandomForestRegressor(n_estimators=100, min_samples_leaf=5, random_state=123))\n",
        "\n",
        "# Run DML model with nfolds folds of cross-fitting (computationally intensive)\n",
        "result_RF = dml(Z, D, Y, modely, modeld, nfolds=5, classifier=False, time = time, clu = clu, cluster = True)\n",
        "table_RF = summary(*result_RF, Z,D, y, name = 'RF')\n",
        "table_RF"
      ],
      "metadata": {
        "id": "bBRrdvgwfbHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Networks"
      ],
      "metadata": {
        "id": "HcmnILDPqdQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DML with NNs\n",
        "modely = make_pipeline(StandardScaler(),\n",
        "                       MLPRegressor((16, 16,), 'relu',\n",
        "                                    learning_rate_init=0.01,\n",
        "                                    batch_size=10, max_iter=100))\n",
        "modeld = make_pipeline(StandardScaler(),\n",
        "                       MLPRegressor((16, 16,), 'relu',\n",
        "                                    learning_rate_init=0.01,\n",
        "                                    batch_size=10, max_iter=100))\n",
        "\n",
        "# Run DML model with nfolds folds of cross-fitting\n",
        "result_NN = dml(Z, D, Y, modely, modeld, nfolds=5, classifier=False, time = time, clu = clu, cluster = True)\n",
        "table_NN = summary(*result_NN, Z,D, y, name = 'NN')\n",
        "table_NN"
      ],
      "metadata": {
        "id": "ke7GwmzBqfoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.033629,
          "end_time": "2021-07-23T16:28:25.305430",
          "exception": false,
          "start_time": "2021-07-23T16:28:25.271801",
          "status": "completed"
        },
        "tags": [],
        "id": "IVOS8G70u-SK"
      },
      "source": [
        "We conclude that the gun ownership rates are related to gun homicide rates - if gun ownership increases by 1% relative\n",
        "to a trend then the predicted gun homicide rate goes up by about 0.20% controlling for counties' characteristics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.033891,
          "end_time": "2021-07-23T16:28:25.372853",
          "exception": false,
          "start_time": "2021-07-23T16:28:25.338962",
          "status": "completed"
        },
        "tags": [],
        "id": "gTGBSqqfu-SW"
      },
      "source": [
        "Finally, let's see which method is best. We computed the RMSE for predicting D and Y above, so let's see which of the methods works better.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmses = pd.concat([table_OLS, table_RLasso, table_post, table_LassoCV, table_ENetCV, table_RidgeCV, table_RF, table_NN], axis=0).iloc[:,-2:]\n",
        "rmses"
      ],
      "metadata": {
        "id": "syua99Emazgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.033769,
          "end_time": "2021-07-23T16:28:25.543748",
          "exception": false,
          "start_time": "2021-07-23T16:28:25.509979",
          "status": "completed"
        },
        "tags": [],
        "id": "TG9y9_Bpu-SX"
      },
      "source": [
        "It looks like the best method for predicting D is ElasticNetCV, and the best method for predicting Y is CV Ridge.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DML with Bests:\n",
        "modely = make_pipeline(StandardScaler(), RidgeCV(cv=cv))\n",
        "modeld = make_pipeline(StandardScaler(), ElasticNetCV(l1_ratio = 0.5, cv=cv))\n",
        "\n",
        "# Run DML model with nfolds folds of cross-fitting\n",
        "result_best = dml(Z, D, Y, modely, modeld, nfolds=5, classifier=False, time = time, clu = clu, cluster = True)\n",
        "table_best = summary(*result_best, Z,D, y, name = 'Best')\n",
        "table_best"
      ],
      "metadata": {
        "id": "Ynwra0p7g988"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.039349,
          "end_time": "2021-07-23T16:28:55.622579",
          "exception": false,
          "start_time": "2021-07-23T16:28:55.583230",
          "status": "completed"
        },
        "tags": [],
        "id": "hcw2mCtPu-SX"
      },
      "source": [
        "Let's organize the results in a table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-23T16:28:55.696769Z",
          "iopub.status.busy": "2021-07-23T16:28:55.695588Z",
          "iopub.status.idle": "2021-07-23T16:28:55.754783Z",
          "shell.execute_reply": "2021-07-23T16:28:55.753576Z"
        },
        "papermill": {
          "duration": 0.097853,
          "end_time": "2021-07-23T16:28:55.754924",
          "exception": false,
          "start_time": "2021-07-23T16:28:55.657071",
          "status": "completed"
        },
        "tags": [],
        "id": "HsUAx8cLu-SX"
      },
      "outputs": [],
      "source": [
        "table = pd.concat([table_OLS, table_RLasso, table_post, table_LassoCV, table_ENetCV, table_RidgeCV, table_RF, table_NN, table_best], axis=0).iloc[:,0:2]\n",
        "table = pd.concat([pd.DataFrame({'estimate': [simple_clu.params[0]], 'stderr': [simple_clu.std_errors[0]]}, index = [\"Baseline (Y~D)\"]),\n",
        "                    pd.DataFrame({'estimate': [all_clu.params[0]], 'stderr': [all_clu.std_errors[0]]}, index = [\"Baseline (Y~D+Z)\"]),\n",
        "                    table],axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(table)"
      ],
      "metadata": {
        "id": "C5Yok88Dlgw6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 663.673787,
      "end_time": "2021-07-23T16:28:56.086168",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-07-23T16:17:52.412381",
      "version": "2.2.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}