{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Andreas Haupt, Alexander Quispe, Anzony Quispe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "051d70d956493feee0c6d64651c6a088724dca2a",
    "papermill": {
     "duration": 0.010774,
     "end_time": "2021-02-15T11:01:41.782833",
     "exception": false,
     "start_time": "2021-02-15T11:01:41.772059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Penalized Linear Regressions: A Simulation Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010616,
     "end_time": "2021-02-15T11:01:41.804126",
     "exception": false,
     "start_time": "2021-02-15T11:01:41.793510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Generating Process: Approximately Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "p = 400\n",
    "Z = np.random.uniform(low=0, high=1 ,size=n) - 1/2 \n",
    "W = (np.random.uniform(low = 0, high = 1, size=n*p) - 1/2).reshape(n, p)\n",
    "\n",
    "beta = ((1/np.arange(1, p + 1 )) ** 2)\n",
    "gX = np.exp( 4 * Z ) + (W @ beta)\n",
    "X = np.concatenate( ( Z.reshape(Z.size, 1), Z.reshape(Z.size, 1) \\\n",
    "                     ** 2, Z.reshape(Z.size, 1) ** 3, W ) , axis = 1 )\n",
    "\n",
    "mean = 0\n",
    "sd = 1\n",
    "Y = gX + np.random.normal(mean, sd, n)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle(r\"$Y$ vs. $g(X)$\")\n",
    "ax = fig.add_subplot(111)\n",
    "plt.scatter( Y, gX)\n",
    "plt.xlabel(r\"$g(X)$\")\n",
    "plt.ylabel(r\"$Y$\")\n",
    "plt.show()\n",
    "\n",
    "print( f\"theoretical R^2:, {np.var(gX) / np.var( Y )}\" ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should know that `cv.glmnet` function in r **standarize** ***X*** data by default. So, we have to standarize our data before the execution of sklearn package. The **normalize** parameter will help for this. However, the function cv.glamnet  is also standarizing the **Y** [variable](https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html) and then unstadarize the coefficients from the regression. To do this with sklearn, we will standarize the **Y** variable before fitting with **StandardScaler** function. Finally, the r-function uses 10 folds by default so we will adjust our model to use **cv=10** ten folds.\\\n",
    "\\\n",
    "The parameter **l1_ratio** corresponds to **alpha** in the glmnet R package while **alpha** corresponds to the **lambda** parameter in **glmnet**. Specifically, **l1_ratio = 1** is the lasso penalty. Currently, **l1_ratio <= 0.01** is not reliable, unless you supply your own sequence of **alpha**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeCV, ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Y variable\n",
    "Y = Y.reshape(1,-1)\n",
    "# Scalar distribution\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(Y)\n",
    "std_Y = scaler.transform(Y)\n",
    "\n",
    "# Regressions\n",
    "fit_lasso_cv = LassoCV(cv = 10 , random_state = 0 , normalize = True ).fit( X, std_Y.ravel() )\n",
    "fit_ridge = ElasticNetCV( cv = 10 , normalize = True , random_state = 0 , l1_ratio = 0.0001 ).fit( X, std_Y.ravel())\n",
    "fit_elnet = ElasticNetCV( cv = 10 , normalize = True , random_state = 0 , l1_ratio = 0.5, max_iter = 100000 ).fit( X, std_Y.ravel())\n",
    "\n",
    "# Predictions\n",
    "yhat_lasso_cv = scaler.inverse_transform( fit_lasso_cv.predict( X ) )\n",
    "yhat_ridge = scaler.inverse_transform( fit_ridge.predict( X ) )\n",
    "yhat_elnet = scaler.inverse_transform( fit_elnet.predict( X ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_lasso_cv = sm.OLS( ((gX - yhat_lasso_cv)**2 ) , np.ones( yhat_lasso_cv.shape )  ).fit().summary2().tables[1].round(3)\n",
    "MSE_ridge = sm.OLS( ((gX - yhat_ridge)**2 ) , np.ones( yhat_ridge.size )  ).fit().summary2().tables[1].round(3)\n",
    "MSE_elnet = sm.OLS( ((gX - yhat_elnet)**2 ) , np.ones( yhat_elnet.size )  ).fit().summary2().tables[1].round(3)\n",
    "# our coefficient of MSE_elnet are far from r output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01429,
     "end_time": "2021-02-15T11:01:45.388902",
     "exception": false,
     "start_time": "2021-02-15T11:01:45.374612",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we compute the lasso and ols post lasso using plug-in choices for penalty levels, using package hdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rlasso functionality: it is searching the right set of regressors. This function was made for the case of ***p*** regressors and ***n*** observations where ***p >>>> n***. It assumes that the error is i.i.d. The errors may be non-Gaussian or heteroscedastic.\\\n",
    "The post lasso function makes OLS with the selected ***T*** regressors.\n",
    "To select those parameters, they use $\\lambda$ as variable to penalize\\\n",
    "**Funny thing: the function rlasso was named like that because it is the \"rigorous\" Lasso.**\\\n",
    "We find a Python code that tries to replicate the main function of hdm r-package. I was made by [Max Huppertz](https://maxhuppertz.github.io/code/). His library is this [repository](https://github.com/maxhuppertz/hdmpy). Download its repository and copy this folder to your site-packages folder. In my case it is located here ***C:\\Python\\Python38\\Lib\\site-packages*** ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to install this package ***pip install multiprocess***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdmpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_rlasso = hdmpy.rlasso(X, Y, post = False)\n",
    "fit_rlasso_post = hdmpy.rlasso(X, Y, post = True)\n",
    "\n",
    "yhat_rlasso = Y - fit_rlasso.est['residuals'].reshape( Y.size,  )\n",
    "yhat_rlasso_post = Y - fit_rlasso_post.est['residuals'].reshape( Y.size ,  )\n",
    "\n",
    "MSE_lasso = sm.OLS( ((gX - yhat_rlasso)**2 ) , np.ones( yhat_rlasso.size )  ).fit().summary2().tables[1].round(3)\n",
    "MSE_lasso_post = sm.OLS( ((gX - yhat_rlasso_post)**2 ) , np.ones( yhat_rlasso_post.size )  ).fit().summary2().tables[1].round(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lava_predict( x, y, iteration = 5 ):\n",
    "    \n",
    "    g1_rlasso = hdmpy.rlasso( x, y , post = False )\n",
    "    g1 = y - g1_rlasso.est['residuals'].reshape( g1_rlasso.est['residuals'].size, )\n",
    "    \n",
    "    new_dep_var = y-g1\n",
    "    new_dep_var_vec = new_dep_var.reshape( new_dep_var.size, 1 )\n",
    "    \n",
    "    # Scalar distribution\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit( new_dep_var_vec )\n",
    "    std_new_dep_var_vec = scaler.transform( new_dep_var_vec )\n",
    "    \n",
    "    fit_ridge_m1 = ElasticNetCV( cv = 10 , normalize = True , random_state = 0 , l1_ratio = 0.0001, alphas = np.array([20]) ).fit( x, std_new_dep_var_vec )\n",
    "    m1 = scaler.inverse_transform( fit_ridge_m1.predict( x ) )\n",
    "    \n",
    "    i = 1\n",
    "    while i <= iteration:\n",
    "        \n",
    "        g1_rlasso = hdmpy.rlasso( x, y , post = False )\n",
    "        g1 = y - g1_rlasso.est['residuals'].reshape( g1_rlasso.est['residuals'].size, )\n",
    "\n",
    "        new_dep_var = y-g1\n",
    "        new_dep_var_vec = new_dep_var.reshape( new_dep_var.size, 1 )\n",
    "\n",
    "        # Scalar distribution\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit( new_dep_var_vec )\n",
    "        std_new_dep_var_vec = scaler.transform( new_dep_var_vec )\n",
    "\n",
    "        fit_ridge_m1 = ElasticNetCV( cv = 10 , normalize = True , random_state = 0 , l1_ratio = 0.0001, alphas = np.array([20]) ).fit( x, std_new_dep_var_vec )\n",
    "        m1 = scaler.inverse_transform( fit_ridge_m1.predict( x ) )\n",
    "        \n",
    "        i = i + 1\n",
    "        \n",
    "    return ( g1 + m1 )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_lava = lava_predict( X, Y )\n",
    "yhat_lava"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02899,
     "end_time": "2021-02-15T11:01:56.880825",
     "exception": false,
     "start_time": "2021-02-15T11:01:56.851835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next we code up lava, which alternates the fitting of lasso and ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_lava = lava_predict( X, Y )\n",
    "MSE_lava = sm.OLS( ((gX - yhat_lava)**2 ) , np.ones( yhat_lava.size )  ).fit().summary2().tables[1].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_lava"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table2 = np.zeros( (6, 2) )\n",
    "\n",
    "table2[0, 0:] = MSE_lasso_cv.iloc[0, 0:2].to_list()\n",
    "table2[1, 0:] = MSE_ridge.iloc[0, 0:2].to_list()\n",
    "table2[2, 0:] = MSE_elnet.iloc[0, 0:2].to_list()\n",
    "table2[3, 0:] = MSE_lasso.iloc[0, 0:2].to_list()\n",
    "table2[4, 0:] = MSE_lasso_post.iloc[0, 0:2].to_list()\n",
    "table2[5, 0:] = MSE_lava.iloc[0, 0:2].to_list()\n",
    "\n",
    "\n",
    "\n",
    "table2_pandas = pd.DataFrame( table2, columns = [ \"MSA\",\"S.E. for MSA\" ])\n",
    "table2_pandas.index = [ \"Cross-Validated Lasso\",\\\n",
    "                       \"Cross-Validated Ridge\", \"Cross-Validated elnet\",\\\n",
    "                       \"Lasso\", \"Post-Lasso\", \"Lava\" ]\n",
    "table2_pandas = table2_pandas.round(3)\n",
    "table2_html = table2_pandas.to_html()\n",
    "table2_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.scatter( gX, gX , marker = '.', c = 'black' )\n",
    "ax1.scatter( gX, yhat_rlasso , marker = 'D' , c = 'red' , label = 'rLasso' )\n",
    "ax1.scatter( gX, yhat_rlasso_post , marker = '^' , c = 'green' , label = 'Post-rLasso')\n",
    "ax1.scatter( gX, yhat_lasso_cv , marker = 'o' , c = 'blue' , label = 'CV Lasso')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018842,
     "end_time": "2021-02-15T11:02:51.941852",
     "exception": false,
     "start_time": "2021-02-15T11:02:51.923010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Generating Process: Approximately Sparse + Small Dense Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "p = 400\n",
    "\n",
    "Z = np.random.uniform( low = 0 , high = 1 , size = n) - 1/2 \n",
    "\n",
    "W = ( np.random.uniform( low = 0 , high = 1 , size = n * p ) - 1/2 ).\\\n",
    "        reshape( n , p )\n",
    "mean = 0\n",
    "sd = 1\n",
    "\n",
    "beta = ((np.random.normal( mean , sd, p )) * 0.2)\n",
    "gX = np.exp( 4 * Z ) + (W @ beta)\n",
    "X = np.concatenate( ( Z.reshape(Z.size, 1), Z.reshape(Z.size, 1) \\\n",
    "                     ** 2, Z.reshape(Z.size, 1) ** 3, W ) , axis = 1 )\n",
    "random.seed(2)\n",
    "Y = gX + np.random.normal( mean , sd, n )\n",
    "\n",
    "# We use package Glmnet to carry out predictions using cross-validated lasso, ridge, and elastic net\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Y vs g(X)')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.scatter( Y, gX)\n",
    "plt.xlabel('g(X)')\n",
    "plt.ylabel('Y')\n",
    "plt.show()\n",
    "\n",
    "print( f\"theoretical R2:, {np.var(gX) / np.var( Y )}\" ) \n",
    "\n",
    "np.var(gX) / np.var( Y ) #theoretical R-square in the simulation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Y variable\n",
    "Y_vec = Y.reshape( Y.size, 1)\n",
    "\n",
    "# Scalar distribution\n",
    "scaler = StandardScaler()\n",
    "scaler.fit( Y_vec )\n",
    "std_Y = scaler.transform( Y_vec )\n",
    "\n",
    "# Regressions\n",
    "fit_lasso_cv = LassoCV(cv = 10 , random_state = 0 , normalize = True ).fit( X, std_Y )\n",
    "fit_ridge = ElasticNetCV( cv = 10 , normalize = True , random_state = 0 , l1_ratio = 0.0001 ).fit( X, std_Y )\n",
    "fit_elnet = ElasticNetCV( cv = 10 , normalize = True , random_state = 0 , l1_ratio = 0.5, max_iter = 100000 ).fit( X, std_Y )\n",
    "\n",
    "# Predictions\n",
    "yhat_lasso_cv = scaler.inverse_transform( fit_lasso_cv.predict( X ) )\n",
    "yhat_ridge = scaler.inverse_transform( fit_ridge.predict( X ) )\n",
    "yhat_elnet = scaler.inverse_transform( fit_elnet.predict( X ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_lasso_cv = sm.OLS( ((gX - yhat_lasso_cv)**2 ) , np.ones( yhat_lasso_cv.shape )  ).fit().summary2().tables[1].round(3)\n",
    "MSE_ridge = sm.OLS( ((gX - yhat_ridge)**2 ) , np.ones( yhat_ridge.size )  ).fit().summary2().tables[1].round(3)\n",
    "MSE_elnet = sm.OLS( ((gX - yhat_elnet)**2 ) , np.ones( yhat_elnet.size )  ).fit().summary2().tables[1].round(3)\n",
    "# our coefficient of MSE_elnet are far from r output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_rlasso = hdmpy.rlasso(X, Y, post = False)\n",
    "fit_rlasso_post = hdmpy.rlasso(X, Y, post = True)\n",
    "\n",
    "yhat_rlasso = Y - fit_rlasso.est['residuals'].reshape( Y.size,  )\n",
    "yhat_rlasso_post = Y - fit_rlasso_post.est['residuals'].reshape( Y.size ,  )\n",
    "\n",
    "MSE_lasso = sm.OLS( ((gX - yhat_rlasso)**2 ) , np.ones( yhat_rlasso.size )  ).fit().summary2().tables[1].round(3)\n",
    "MSE_lasso_post = sm.OLS( ((gX - yhat_rlasso_post)**2 ) , np.ones( yhat_rlasso_post.size )  ).fit().summary2().tables[1].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lava_predict( x, y, iteration = 5 ):\n",
    "    \n",
    "    g1_rlasso = hdmpy.rlasso( x, y , post = False )\n",
    "    g1 = y - g1_rlasso.est['residuals'].reshape( g1_rlasso.est['residuals'].size, )\n",
    "    \n",
    "    new_dep_var = y-g1\n",
    "    new_dep_var_vec = new_dep_var.reshape( new_dep_var.size, 1 )\n",
    "    \n",
    "    # Scalar distribution\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit( new_dep_var_vec )\n",
    "    std_new_dep_var_vec = scaler.transform( new_dep_var_vec )\n",
    "    \n",
    "    fit_ridge_m1 = ElasticNetCV( cv = 10 , normalize = True , random_state = 0 , l1_ratio = 0.0001, alphas = np.array([20]) ).fit( x, std_new_dep_var_vec )\n",
    "    m1 = scaler.inverse_transform( fit_ridge_m1.predict( x ) )\n",
    "    \n",
    "    i = 1\n",
    "    while i <= iteration:\n",
    "        \n",
    "        g1_rlasso = hdmpy.rlasso( x, y , post = False )\n",
    "        g1 = y - g1_rlasso.est['residuals'].reshape( g1_rlasso.est['residuals'].size, )\n",
    "\n",
    "        new_dep_var = y-g1\n",
    "        new_dep_var_vec = new_dep_var.reshape( new_dep_var.size, 1 )\n",
    "\n",
    "        # Scalar distribution\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit( new_dep_var_vec )\n",
    "        std_new_dep_var_vec = scaler.transform( new_dep_var_vec )\n",
    "\n",
    "        fit_ridge_m1 = ElasticNetCV( cv = 10 , normalize = True , random_state = 0 , l1_ratio = 0.0001, alphas = np.array([20]) ).fit( x, std_new_dep_var_vec )\n",
    "        m1 = scaler.inverse_transform( fit_ridge_m1.predict( x ) )\n",
    "        \n",
    "        i = i + 1\n",
    "        \n",
    "    return ( g1 + m1 )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_lava = lava_predict( X, Y )\n",
    "MSE_lava = sm.OLS( ((gX - yhat_lava)**2 ) , np.ones( yhat_lava.size )  ).fit().summary2().tables[1].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table2 = np.zeros( (6, 2) )\n",
    "\n",
    "table2[0, 0:] = MSE_lasso_cv.iloc[0, 0:2].to_list()\n",
    "table2[1, 0:] = MSE_ridge.iloc[0, 0:2].to_list()\n",
    "table2[2, 0:] = MSE_elnet.iloc[0, 0:2].to_list()\n",
    "table2[3, 0:] = MSE_lasso.iloc[0, 0:2].to_list()\n",
    "table2[4, 0:] = MSE_lasso_post.iloc[0, 0:2].to_list()\n",
    "table2[5, 0:] = MSE_lava.iloc[0, 0:2].to_list()\n",
    "\n",
    "\n",
    "\n",
    "table2_pandas = pd.DataFrame( table2, columns = [ \"MSA\",\"S.E. for MSA\" ])\n",
    "table2_pandas.index = [ \"Cross-Validated Lasso\",\\\n",
    "                       \"Cross-Validated Ridge\", \"Cross-Validated elnet\",\\\n",
    "                       \"Lasso\", \"Post-Lasso\", \"Lava\" ]\n",
    "table2_pandas = table2_pandas.round(3)\n",
    "table2_html = table2_pandas.to_html()\n",
    "table2_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.scatter( gX, gX , marker = '.', c = 'black' )\n",
    "ax1.scatter( gX, yhat_rlasso , marker = 'D' , c = 'red' , label = 'rLasso' )\n",
    "ax1.scatter( gX, yhat_rlasso_post , marker = '^' , c = 'green' , label = 'Post-rLasso')\n",
    "ax1.scatter( gX, yhat_lasso_cv , marker = 'o' , c = 'blue' , label = 'CV Lasso')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
