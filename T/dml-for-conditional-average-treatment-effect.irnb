{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"3.6.3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  DML for CATE\n\nThis is a simple demonstration of Debiased Machine Learning estimator for the Conditional Average Treatment Effect. \nGoal is to estimate the effect of 401(k) eligibility on net financial assets for each value of income. \nThe method is based on the following paper. \n\n* Title:  Debiased Machine Learning of Conditional Average Treatment Effect and Other Causal Functions\n\n* Authors: Semenova, Vira and Chernozhukov, Victor. \n\n* Arxiv version: https://arxiv.org/pdf/1702.06240.pdf\n\n* Published version with replication code: https://academic.oup.com/ectj/advance-article/doi/10.1093/ectj/utaa027/5899048\n","metadata":{"execution":{"iopub.status.busy":"2021-05-24T12:51:59.763661Z","iopub.execute_input":"2021-05-24T12:51:59.765554Z","iopub.status.idle":"2021-05-24T12:51:59.866888Z"}}},{"cell_type":"markdown","source":"Background\n\nThe target function is Conditional Average Treatment Effect, defined as \n\n$$ g(x)=E [ Y(1) - Y(0) |X=x], $$ \n\nwhere $Y(1)$ and $Y(0)$ are potential outcomes in treated and control group. In our case, $Y(1)$ is the potential Net Financial Assets if a subject is eligible for 401(k), and $Y(0)$ is the potential Net Financial Assets if a subject is ineligible. $X$ is a covariate of interest, in this case, income.\n$ g(x)$ shows expected effect of eligibility on NET TFA for a subject whose income level is $x$.\n\n\n\nIf eligibility indicator is independent of $Y(1), Y(0)$, given pre-401-k assignment characteristics $Z$, the function can expressed in terms of observed data (as opposed to hypothetical, or potential outcomes). Observed data consists of  realized NET TFA $Y = D Y(1) + (1-D) Y(0)$, eligibility indicator $D$, and covariates $Z$ which includes $X$, income. The expression for $g(x)$ is\n\n$$ g(x) = E [ Y (\\eta_0) \\mid X=x], $$\nwhere the transformed outcome variable is\n\n$$Y (\\eta) = \\dfrac{D}{s(Z)} \\left( Y - \\mu(1,Z) \\right) - \\dfrac{1-D}{1-s(Z)} \\left( Y - \\mu(0,Z) \\right) + \\mu(1,Z) - \\mu(0,Z),$$\n\nthe probability of eligibility is \n\n$$s_0(z) = Pr (D=1 \\mid Z=z),$$ \n\nthe expected net financial asset given $D =d \\in \\{1,0\\}$ and $Z=z$ is\n\n$$ \\mu(d,z) = E[ Y \\mid Z=z, D=d]. $$\n\nOur goal is to estimate $g(x)$.\n\n\nIn step 1, we estimate the unknown functions $s_0(z),  \\mu(1,z),  \\mu(0,z)$ and plug them into $Y (\\eta)$.\n\n\nIn step 2, we approximate the function $g(x)$ by a linear combination of basis functions:\n\n$$ g(x) = p(x)' \\beta_0, $$\n\n\nwhere $p(x)$ is a vector of polynomials or splines and\n\n$$ \\beta_0 = (E p(X) p(X))^{-1} E p(X) Y (\\eta_0) $$\n\nis the best linear predictor. We report\n\n$$\n\\widehat{g}(x) = p(x)' \\widehat{\\beta},\n$$\n\nwhere $\\widehat{\\beta}$ is the ordinary least squares estimate of $\\beta_0$ defined on the random sample $(X_i, D_i, Y_i)_{i=1}^N$\n\n$$\n\t\\widehat{\\beta} :=\\left( \\dfrac{1}{N} \\sum_{i=1}^N p(X_i) p(X_i)' \\right)^{-1} \\dfrac{1}{N} \\sum_{i=1}^N  p(X_i)Y_i(\\widehat{\\eta})\n$$\n\n\n\n\n\n\n","metadata":{}},{"cell_type":"code","source":"## load packages\nrm(list=ls())\nlibrary(foreign)\nlibrary(quantreg)\nlibrary(splines)\nlibrary(lattice)\n#library(mnormt);\nlibrary(Hmisc)\nlibrary(fda);\nlibrary(hdm)\nlibrary(randomForest)\nlibrary(ranger)\nlibrary(sandwich)","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","execution":{"iopub.status.busy":"2021-06-17T23:22:23.184728Z","iopub.execute_input":"2021-06-17T23:22:23.212298Z","iopub.status.idle":"2021-06-17T23:22:25.857077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## 401k dataset\ndata(pension)\npension$net_tfa<-pension$net_tfa/10000\n## covariate of interest -- log income -- \npension$inc = log(pension$inc)\n#pension$inc[is.na(pension$inc)]<-0\npension<-pension[!is.na(pension$inc) & pension$inc!=-Inf & pension$inc !=Inf,]\n\n\n## outcome variable -- total net financial assets\nY=pension$net_tfa\n## binary treatment --  indicator of 401(k) eligibility\nD=pension$e401\n\n\nX=pension$inc\n## target parameter is CATE = E[ Y(1) - Y(0) | X] \n\n\n## raw covariates so that Y(1) and Y(0) are independent of D given Z\nZ = pension[,c(\"age\",\"inc\",\"fsize\",\"educ\",\"male\",\"db\",\"marr\",\"twoearn\",\"pira\",\"hown\",\"hval\",\"hequity\",\"hmort\",\n              \"nohs\",\"hs\",\"smcol\")]\n\n\ny_name   <- \"net_tfa\";\nd_name    <- \"e401\";\nform_z    <- \"(poly(age, 6) + poly(inc, 8) + poly(educ, 4) + poly(fsize,2) + as.factor(marr) + as.factor(twoearn) + as.factor(db) + as.factor(pira) + as.factor(hown))^2\";\n\n\n\ncat(sprintf(\"\\n sample size is %g \\n\", length(Y) ))\ncat(sprintf(\"\\n num raw covariates z is %g \\n\", dim(Z)[2] ))","metadata":{"execution":{"iopub.status.busy":"2021-06-17T23:22:29.81323Z","iopub.execute_input":"2021-06-17T23:22:29.815342Z","iopub.status.idle":"2021-06-17T23:22:30.080343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In Step 1, we estimate three functions:\n\n1. probability of treatment assignment $s_0(z)$ \n\n2.-3. regression functions $\\mu_0(1,z)$ and $\\mu_0(0,z)$.  \n\nWe use the cross-fitting procedure with $K=2$ holds. For definition of cross-fitting with $K$ folds, check the sample splitting in ```DML2.for.PLM``` function defined in https://www.kaggle.com/victorchernozhukov/debiased-ml-for-partially-linear-model-in-r\n\nFor each function, we try random forest.\n","metadata":{}},{"cell_type":"markdown","source":"First Stage: estimate $\\mu_0(1,z)$ and $\\mu_0(0,z)$ and $s_0(z)$ by lasso","metadata":{}},{"cell_type":"code","source":"\nfirst_stage_lasso<-function(data,d_name,y_name, form_z, seed=1) {\n\n  # Sample size\n  N<-dim(data)[1]\n  # Estimated regression function in control group\n  mu0.hat<-rep(1,N) \n  # Estimated regression function in treated group\n  mu1.hat<-rep(1,N) \n  # Propensity score\n  s.hat<-rep(1,N)\n  seed=1\n  ## define sample splitting\n  set.seed(seed)\n  inds.train=sample(1:N,floor(N/2))\n  inds.eval=setdiff(1:N,inds.train)\n\n  print (\"Estimate treatment probability, first half\")\n  ## conditional probability of 401 k eligibility (i.e., propensity score) based on random forest\n  fitted.lasso.pscore<-rlassologit(as.formula(paste0(d_name,\"~\",form_z )),data=data[inds.train,])\n\n  s.hat[inds.eval]<-predict(fitted.lasso.pscore,data[inds.eval,],type=\"response\")\n  print (\"Estimate treatment probability, second half\")\n  fitted.lasso.pscore<-rlassologit(as.formula(paste0(d_name,\"~\",form_z )),data=data[inds.eval,])\n  s.hat[inds.train]<-predict( fitted.lasso.pscore,data[inds.train,],type=\"response\")\n\n\n\n\n\n  data1<-data\n  data1[,d_name]<-1\n\n  data0<-data\n  data0[,d_name]<-0\n\n  print (\"Estimate expectation function, first half\") \n  fitted.lasso.mu<-rlasso(as.formula(paste0(y_name,\"~\",d_name,\"+(\",form_z,\")\" )),data=data[inds.train,])\n  mu1.hat[inds.eval]<-predict( fitted.lasso.mu,data1[inds.eval,])\n  mu0.hat[inds.eval]<-predict( fitted.lasso.mu,data0[inds.eval,]) \n  \n  print (\"Estimate expectation function, second half\") \n  fitted.lasso.mu<-rlasso(as.formula(paste0(y_name,\"~\",d_name,\"+(\",form_z,\")\" )),data=data[inds.eval,])\n  mu1.hat[inds.train]<-predict( fitted.lasso.mu,data1[inds.train,])\n  mu0.hat[inds.train]<-predict( fitted.lasso.mu,data0[inds.train,]) \n \n  return (list(mu1.hat=mu1.hat,\n              mu0.hat=mu0.hat,\n              s.hat=s.hat))\n    \n}","metadata":{"execution":{"iopub.status.busy":"2021-06-17T23:22:34.034028Z","iopub.execute_input":"2021-06-17T23:22:34.035487Z","iopub.status.idle":"2021-06-17T23:22:34.048805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First Stage: estimate $\\mu_0(1,z)$ and $\\mu_0(0,z)$ and $s_0(z)$ by random forest","metadata":{}},{"cell_type":"code","source":"first_stage_rf<-function(Y,D,Z,seed=1) {\n\n  # Sample size\n  N<-length(D)\n  # Estimated regression function in control group\n  mu0.hat<-rep(1,N) \n  # Estimated regression function in treated group\n  mu1.hat<-rep(1,N) \n  # Propensity score\n  s.hat<-rep(1,N)\n    \n    \n  ## define sample splitting\n   set.seed(seed)\n  inds.train=sample(1:N,floor(N/2))\n  inds.eval=setdiff(1:N,inds.train)\n\n    print (\"Estimate treatment probability, first half\")\n  ## conditional probability of 401 k eligibility (i.e., propensity score) based on random forest\n    D.f<-as.factor(as.character(D))\n   fitted.rf.pscore<-randomForest(Z,D.f,subset=inds.train)\n   s.hat[inds.eval]<-predict(fitted.rf.pscore,Z[inds.eval,],type=\"prob\")[,2]\n    print (\"Estimate treatment probability, second half\")\n   fitted.rf<-randomForest(Z,D.f,subset=inds.eval) \n    s.hat[inds.train]<-predict(fitted.rf.pscore,Z[inds.train,],type=\"prob\")[,2]\n    \n  ## conditional expected net financial assets (i.e.,  regression function) based on random forest\n  \n  covariates<-cbind(Z,D)\n    \n  covariates1<-cbind(Z,D=rep(1,N))\n  covariates0<-cbind(Z,D=rep(0,N))\n  \n  print (\"Estimate expectation function, first half\") \n  fitted.rf.mu<-randomForest(cbind(Z,D),Y,subset=inds.train)\n  mu1.hat[inds.eval]<-predict( fitted.rf.mu,covariates1[inds.eval,])\n  mu0.hat[inds.eval]<-predict( fitted.rf.mu,covariates0[inds.eval,]) \n  \n  print (\"Estimate expectation function, second half\") \n   fitted.rf.mu<-randomForest(cbind(Z,D),Y,subset=inds.eval) \n   mu1.hat[inds.train]<-predict( fitted.rf.mu,covariates1[inds.train,])\n   mu0.hat[inds.train]<-predict( fitted.rf.mu,covariates0[inds.train,]) \n \n  return (list(mu1.hat=mu1.hat,\n              mu0.hat=mu0.hat,\n              s.hat=s.hat))\n    \n}","metadata":{"execution":{"iopub.status.busy":"2021-06-17T23:22:39.936225Z","iopub.execute_input":"2021-06-17T23:22:39.937654Z","iopub.status.idle":"2021-06-17T23:22:39.949402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In Step 2, we approximate $Y(\\eta_0)$ by a vector of basis functions. There are two use cases:\n****\n2.A. Group Average Treatment Effect, described above\n\n\n2.B. Average Treatment Effect conditional on income value. There are three smoothing options:\n\n1. splines offered in ```least_squares_splines```\n\n2. orthogonal polynomials with the highest degree chosen by cross-validation ```least_squares_series```\n\n3. standard polynomials with the highest degree input by user ```least_squares_series_old```\n\n\nThe default option is option 3.","metadata":{"trusted":true}},{"cell_type":"markdown","source":"2.A. The simplest use case of Conditional Average Treatment Effect is GATE, or Group Average Treatment Effect. Partition the support of income as\n\n$$ - \\infty = \\ell_0 < \\ell_1 < \\ell_2 \\dots \\ell_K = \\infty $$\n\ndefine intervals $I_k = [ \\ell_{k-1}, \\ell_{k})$. Let $X$ be income covariate. For $X$, define a group indicator \n\n$$ G_k(X) = 1[X \\in I_k], $$\n\nand the vector of basis functions \n\n$$ p(X) = (G_1(X), G_2(X), \\dots, G_K(X)) $$\n\nThen, the Best Linear Predictor $\\beta_0$ vector shows the average treatment effect for each group.","metadata":{}},{"cell_type":"code","source":"## estimate first stage functions by random forest\n## may take a while\nfs.hat.rf = first_stage_rf(Y,D,Z)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T23:22:43.39889Z","iopub.execute_input":"2021-06-17T23:22:43.400377Z","iopub.status.idle":"2021-06-17T23:25:21.477536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=pension$inc\nfs.hat<-fs.hat.rf\nmin_cutoff=0.01\n# regression function\nmu1.hat<-fs.hat[[\"mu1.hat\"]]\nmu0.hat<-fs.hat[[\"mu0.hat\"]]\n# propensity score\ns.hat<-fs.hat[[\"s.hat\"]]\ns.hat<-sapply(s.hat,max,min_cutoff)\n### Construct Orthogonal Signal \n\n\nRobustSignal<-(Y - mu1.hat)*D/s.hat - (Y - mu0.hat)*(1-D)/(1-s.hat) + mu1.hat - mu0.hat","metadata":{"execution":{"iopub.status.busy":"2021-06-17T23:29:29.48508Z","iopub.execute_input":"2021-06-17T23:29:29.486762Z","iopub.status.idle":"2021-06-17T23:29:29.51917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qtmax <- function(C, S=10000, alpha)\n  {;\n   p <- nrow(C);\n   tmaxs <- apply(abs(matrix(rnorm(p*S), nrow = p, ncol = S)), 2, max);\n   return(quantile(tmaxs, 1-alpha));\n  };\n\n# This function computes the square root of a symmetric matrix using the spectral decomposition;\n\n\ngroup_average_treatment_effect<-function(X,Y,max_grid=5,alpha=0.05, B=10000) {\n    \n grid<-quantile(X,probs=c((0:max_grid)/max_grid))\n X.raw<-matrix(NA, nrow=length(Y),ncol=length(grid)-1) \n    \n for (k in 2:((length(grid)))) {\n       X.raw[,k-1]<-sapply(X, function (x) ifelse (x>=grid[k-1] & x<grid[k],1,0) )\n }\n k=length(grid)\n X.raw[,k-1]<-sapply(X, function (x) ifelse (x>=grid[k-1] & x<=grid[k],1,0) )\n                                  \n ols.fit<- lm(Y~X.raw-1)\n coefs   <- coef(ols.fit)\n vars <- names(coefs)\n HCV.coefs <- vcovHC(ols.fit, type = 'HC')\n coefs.se <- sqrt(diag(HCV.coefs)) # White std errors\n ## this is an identity matrix\n                     ## qtmax is simplified\n C.coefs  <- (diag(1/sqrt(diag(HCV.coefs)))) %*% HCV.coefs %*% (diag(1/sqrt(diag(HCV.coefs))));                    \n                 \n                     \n tes  <- coefs\n tes.se <- coefs.se\n tes.cor <- C.coefs\n crit.val <- qtmax(tes.cor,B,alpha);\n                     \n tes.ucb  <- tes + crit.val * tes.se;\n tes.lcb  <- tes - crit.val * tes.se;\n\n tes.uci  <- tes + qnorm(1-alpha/2) * tes.se;\n tes.lci  <- tes + qnorm(alpha/2) * tes.se;\n\n                     \n return(list(beta.hat=coefs, ghat.lower.point=tes.lci, ghat.upper.point=tes.uci,\n           ghat.lower=tes.lcb, ghat.upper= tes.ucb, crit.val=crit.val ))\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-17T23:29:31.606456Z","iopub.execute_input":"2021-06-17T23:29:31.609202Z","iopub.status.idle":"2021-06-17T23:29:31.629475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res<-group_average_treatment_effect(X=X,Y=RobustSignal)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T23:29:33.458131Z","iopub.execute_input":"2021-06-17T23:29:33.459626Z","iopub.status.idle":"2021-06-17T23:29:34.195401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## this code is taken from L1 14.382 taught at MIT\n## author: Mert Demirer\noptions(repr.plot.width=10, repr.plot.height=8)\n\ntes<-res$beta.hat\ntes.lci<-res$ghat.lower.point\ntes.uci<-res$ghat.upper.point\n\ntes.lcb<-res$ghat.lower\ntes.ucb<-res$ghat.upper\ntes.lev<-c('0%-20%', '20%-40%','40%-60%','60%-80%','80%-100%')\n\nplot( c(1,5), las = 2, xlim =c(0.6, 5.4), ylim = c(.05, 2.09),  type=\"n\",xlab=\"Income group\", \n     ylab=\"Average Effect on NET TFA (per 10 K)\", main=\"Group Average Treatment Effects on NET TFA\", xaxt=\"n\");\naxis(1, at=1:5, labels=tes.lev);\nfor (i in 1:5)\n{;\n rect(i-0.2, tes.lci[i], i+0.2,  tes.uci[i], col = NA,  border = \"red\", lwd = 3);    \n rect(i-0.2, tes.lcb[i], i+0.2, tes.ucb[i], col = NA,  border = 4, lwd = 3 );   \n segments(i-0.2, tes[i], i+0.2, tes[i], lwd = 5 );\n};\nabline(h=0);\n\nlegend(2.5, 2.0, c('Regression Estimate', '95% Simultaneous Confidence Interval', '95% Pointwise Confidence Interval'), col = c(1,4,2), lwd = c(4,3,3), horiz = F, bty = 'n', cex=0.8);\n\ndev.off()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T23:29:36.013118Z","iopub.execute_input":"2021-06-17T23:29:36.014791Z","iopub.status.idle":"2021-06-17T23:29:36.401451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"least_squares_splines<-function(X,Y,max_knot=9,norder,nderiv,...) {\n  ## Create technical regressors\n    cv.bsp<-rep(0,max_knot-1)\n    for (knot in 2:max_knot) {\n      breaks<- quantile(X, c(0:knot)/knot)\n      formula.bsp \t<- Y ~ bsplineS(X, breaks =breaks, norder = norder, nderiv = nderiv)[ ,-1]\n      fit\t<- lm(formula.bsp);\n      cv.bsp[knot-1]\t\t<- sum( (fit$res / (1 - hatvalues(fit)) )^2);\n    }\n    ## Number of knots chosen by cross-validation\n    cv_knot<-which.min(cv.bsp)+1\n     breaks<- quantile(X, c(0:cv_knot)/cv_knot)\n   formula.bsp \t<- Y ~ bsplineS(X, breaks =breaks, norder = norder, nderiv = 0)[ ,-1]\n   fit\t<- lm(formula.bsp); \n   \n    \n   return(list(cv_knot=cv_knot,fit=fit))\n}\n\n\nleast_squares_series<-function(X, Y,max_degree,...) {\n \n  cv.pol<-rep(0,max_degree)\n  for (degree in 1:max_degree) {\n    formula.pol \t<- Y ~ poly(X, degree)\n    fit\t<- lm(formula.pol );\n    cv.pol[degree]\t\t<- sum( (fit$res / (1 - hatvalues(fit)) )^2);\n  }\n  ## Number of knots chosen by cross-validation\n  cv_degree<-which.min(cv.pol)\n  ## Estimate coefficients\n  formula.pol \t<- Y ~ poly(X, cv_degree)\n  fit\t<- lm(formula.pol);\n    \n    \n  return(list(fit=fit,cv_degree=cv_degree))\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-17T23:29:39.594018Z","iopub.execute_input":"2021-06-17T23:29:39.595684Z","iopub.status.idle":"2021-06-17T23:29:39.61105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msqrt <- function(C)\n  {;\n  C.eig <- eigen(C);\n  return(C.eig$vectors %*% diag(sqrt(C.eig$values)) %*% solve(C.eig$vectors));\n  };\n\n\ntboot<-function(regressors_grid, Omega.hat ,alpha, B=10000) {\n  \n    \n   numerator_grid<-regressors_grid%*%msqrt( Omega.hat)\n   denominator_grid<-sqrt(diag(regressors_grid%*% Omega.hat%*%t(regressors_grid)))\n    \n   norm_numerator_grid<-numerator_grid\n   for (k in 1:dim(numerator_grid)[1]) {\n       norm_numerator_grid[k,]<-numerator_grid[k,]/denominator_grid[k]\n   }\n   \n   tmaxs <- apply(abs( norm_numerator_grid%*% matrix(rnorm(dim(numerator_grid)[2]*B), nrow = dim(numerator_grid)[2], ncol = B)), 2, max)\n   return(quantile(tmaxs, 1-alpha))\n \n}","metadata":{"execution":{"iopub.status.busy":"2021-06-17T23:29:41.532655Z","iopub.execute_input":"2021-06-17T23:29:41.534418Z","iopub.status.idle":"2021-06-17T23:29:41.549624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"second_stage<-function(fs.hat,Y,D,X,max_degree=3,norder=4,nderiv=0,ss_method=\"poly\",min_cutoff=0.01,alpha=0.05,eps=0.1,...) {\n  \n     X_grid = seq(min(X),max(X),eps)\n     mu1.hat<-fs.hat[[\"mu1.hat\"]]\n    mu0.hat<-fs.hat[[\"mu0.hat\"]]\n    # propensity score\n    s.hat<-fs.hat[[\"s.hat\"]]\n    s.hat<-sapply(s.hat,max,min_cutoff)\n    ### Construct Orthogonal Signal \n\n    RobustSignal<-(Y - mu1.hat)*D/s.hat - (Y - mu0.hat)*(1-D)/(1-s.hat) + mu1.hat - mu0.hat\n\n\n  \n   # Estimate the target function using least squares series\n   if (ss_method == \"ortho_poly\") {\n    res<-least_squares_series(X=X,Y=RobustSignal,eps=0.1,max_degree=max_degree)\n    fit<-res$fit\n    cv_degree<-res$cv_degree\n    regressors_grid<-cbind( rep(1,length(X_grid)), poly(X_grid,cv_degree))   \n    \n  } \n  if (ss_method == \"splines\") {\n      \n    res<-least_squares_splines(X=X,Y=RobustSignal,eps=0.1,norder=norder,nderiv=nderiv)\n    fit<-res$fit\n    cv_knot<-res$cv_knot\n    breaks<- quantile(X, c(0:cv_knot)/cv_knot)  \n    regressors_grid<-cbind( rep(1,length(X_grid)), bsplineS(X_grid, breaks =breaks, norder = norder, nderiv = nderiv)[ ,-1])\n    degree=cv_knot\n \n\n  }\n\n\n  g.hat<-regressors_grid%*%coef(fit)\n \n    \n  HCV.coefs <- vcovHC(fit, type = 'HC') \n  #Omega.hat<-white_vcov(regressors,Y,b.hat=coef(fit))\n  standard_error<-sqrt(diag(regressors_grid%*% HCV.coefs%*%t(regressors_grid)))\n  ### Lower Pointwise CI\n  ghat.lower.point<-g.hat+qnorm(alpha/2)*standard_error\n  ### Upper Pointwise CI\n  ghat.upper.point<-g.hat+qnorm(1-alpha/2)*standard_error\n \n   max_tstat<-tboot(regressors_grid=regressors_grid,  Omega.hat=HCV.coefs,alpha=alpha)\n  \n    \n  ## Lower Uniform CI\n  ghat.lower<-g.hat-max_tstat*standard_error\n  ## Upper Uniform CI\n  ghat.upper<-g.hat+max_tstat*standard_error\n  return(list(ghat.lower=ghat.lower,g.hat=g.hat, ghat.upper=ghat.upper,fit=fit,ghat.lower.point=ghat.lower.point,\n              ghat.upper.point=ghat.upper.point,X_grid=X_grid))\n    \n\n\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-17T23:29:43.135629Z","iopub.execute_input":"2021-06-17T23:29:43.137405Z","iopub.status.idle":"2021-06-17T23:29:43.150866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_plot<-function(res,lowy,highy,degree,ss_method = \"series\",uniform=TRUE,...) {\n\n\n  title=paste0(\"Effect of 401(k) on Net TFA, \", ss_method)\n  X_grid=res$X_grid\n  len = length(X_grid)\n  \n    \n  if (uniform) {\n       group <-c(rep(\"UCI\",len), rep(\"PCI\",len), rep(\"Estimate\",len),rep(\"PCIL\",len),rep(\"UCIL\",len))\n       group_type<- c(rep(\"CI\",len), rep(\"CI\",len), rep(\"Estimate\",len),rep(\"CI\",len),rep(\"CI\",len))\n       group_ci_type<-c(rep(\"Uniform\",len), rep(\"Point\",len), rep(\"Uniform\",len),rep(\"Point\",len),rep(\"Uniform\",len))\n\n     df<-data.frame(income=rep(X_grid,5), outcome = c(res$ghat.lower,res$ghat.lower.point,res$g.hat,res$ghat.upper.point,res$ghat.upper),group=group, group_col = group_type,group_line =group_ci_type )\n       p<-ggplot(data=df)+\n    aes(x=exp(income),y=outcome,colour=group )+\n    theme_bw()+\n    xlab(\"Income\")+\n    ylab(\"Net TFA, (thousand dollars)\")+\n    scale_colour_manual(values=c(\"black\",\"blue\",\"blue\",\"blue\",\"blue\"))+\n    theme(plot.title = element_text(hjust = 0.5),text=element_text(size=20,  family=\"serif\"))+\n    theme(legend.title=element_blank())+\n    theme(legend.position=\"none\")+\n    ylim(low=lowy,high=highy)+\n    geom_line(aes(linetype = group_line),size=1.5)+\n    scale_linetype_manual(values=c(\"dashed\",\"solid\"))+\n    ggtitle(title)  \n  } \n\n  if (!uniform) {\n      group <-c( rep(\"PCI\",len), rep(\"Estimate\",len),rep(\"PCIL\",len))\n      group_type<- c(rep(\"CI\",len), rep(\"Estimate\",len),rep(\"CI\",len))\n     group_ci_type<-c(rep(\"Point\",len), rep(\"Uniform\",len),rep(\"Point\",len))\n      \n       df<-data.frame(income=rep(X_grid,3), outcome = c(res$ghat.lower.point,res$g.hat,res$ghat.upper.point),group=group, group_col = group_type,group_line =group_ci_type )\n   \n        p<-ggplot(data=df)+\n    aes(x=exp(income),y=outcome,colour=group )+\n    theme_bw()+\n    xlab(\"Income\")+\n    ylab(\"Net TFA, (thousand dollars)\")+\n    scale_colour_manual(values=c(\"black\",\"blue\",\"blue\",\"blue\",\"blue\"))+\n    theme(plot.title = element_text(hjust = 0.5),text=element_text(size=20,  family=\"serif\"))+\n    theme(legend.title=element_blank())+\n    theme(legend.position=\"none\")+\n    ylim(low=lowy,high=highy)+\n    geom_line(aes(linetype = group_line),size=1.5)+\n    scale_linetype_manual(values=c(\"dashed\",\"solid\"))+\n    ggtitle(title)   \n\n   }\n\n\n \n  return(p)\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-17T23:30:32.523395Z","iopub.execute_input":"2021-06-17T23:30:32.524854Z","iopub.status.idle":"2021-06-17T23:30:32.538133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_ortho_rf_splines=second_stage(fs.hat=fs.hat.rf,X=X,D=D,Y=Y,ss_method=\"splines\",max_degree=3)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T23:30:34.152061Z","iopub.execute_input":"2021-06-17T23:30:34.153603Z","iopub.status.idle":"2021-06-17T23:30:34.373651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_ortho_rf_ortho_poly=second_stage(fs.hat=fs.hat.rf,X=X,D=D,Y=Y,ss_method=\"ortho_poly\",max_degree=3)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T23:30:35.857481Z","iopub.execute_input":"2021-06-17T23:30:35.858912Z","iopub.status.idle":"2021-06-17T23:30:35.999597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#plot findings:\n\n-- black solid line shows estimated function $p(x)' \\widehat{\\beta}$\n\n-- blue dashed lines show pointwise confidence bands for this function","metadata":{}},{"cell_type":"code","source":"p<-make_plot(res_ortho_rf_ortho_poly,ss_method=\"ortho_poly\",uniform=FALSE, lowy=-10,highy=20)\noptions(repr.plot.width=15, repr.plot.height=10)\nprint(p)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T23:30:38.317509Z","iopub.execute_input":"2021-06-17T23:30:38.318889Z","iopub.status.idle":"2021-06-17T23:30:38.869822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"plot findings:\n\n-- black solid line shows estimated function $p(x)' \\widehat{\\beta}$\n\n-- blue dashed lines show pointwise confidence bands for this function. I.e., for each fixed point $x_0$, i.e., $x_0=1$, they cover $p(x_0)'\\beta_0$ with probability 0.95\n\n-- blue solid lines show  uniform confidence bands for this function. I.e.,  they cover the whole function $x \\rightarrow p(x)'\\beta_0$ with probability 0.95 on some compact range","metadata":{}},{"cell_type":"code","source":"p<-make_plot(res_ortho_rf_ortho_poly,ss_method=\"ortho polynomials\",uniform=TRUE,lowy=-10,highy=25) \noptions(repr.plot.width=15, repr.plot.height=10)\nprint(p)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T23:31:40.758163Z","iopub.execute_input":"2021-06-17T23:31:40.759621Z","iopub.status.idle":"2021-06-17T23:31:41.125637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p<-make_plot(res_ortho_rf_splines,ss_method=\"splines\",uniform=FALSE, lowy=-15,highy=10)\noptions(repr.plot.width=15, repr.plot.height=10)\nprint(p)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T23:30:46.617249Z","iopub.execute_input":"2021-06-17T23:30:46.618764Z","iopub.status.idle":"2021-06-17T23:30:46.973963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p<-make_plot(res_ortho_rf_splines,ss_method=\"splines\",uniform=TRUE,lowy=-20,highy=20) \noptions(repr.plot.width=15, repr.plot.height=10)\nprint(p)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T23:31:26.657033Z","iopub.execute_input":"2021-06-17T23:31:26.658474Z","iopub.status.idle":"2021-06-17T23:31:27.015569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}