{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtRhnrDslwi1"
   },
   "source": [
    "#  DML for CATE\n",
    "\n",
    "This is a simple demonstration of Debiased Machine Learning estimator for the Conditional Average Treatment Effect.\n",
    "Goal is to estimate the effect of 401(k) eligibility on net financial assets for each value of income.\n",
    "The method is based on the following paper.\n",
    "\n",
    "* Title:  Debiased Machine Learning of Conditional Average Treatment Effect and Other Causal Functions\n",
    "\n",
    "* Authors: Semenova, Vira and Chernozhukov, Victor.\n",
    "\n",
    "* Arxiv version: https://arxiv.org/pdf/1702.06240.pdf\n",
    "\n",
    "* Published version with replication code: https://academic.oup.com/ectj/advance-article/doi/10.1093/ectj/utaa027/5899048\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibFWChhelwi4"
   },
   "source": [
    "Background\n",
    "\n",
    "The target function is Conditional Average Treatment Effect, defined as\n",
    "\n",
    "$$ g(x)=E [ Y(1) - Y(0) |X=x], $$\n",
    "\n",
    "where $Y(1)$ and $Y(0)$ are potential outcomes in treated and control group. In our case, $Y(1)$ is the potential Net Financial Assets if a subject is eligible for 401(k), and $Y(0)$ is the potential Net Financial Assets if a subject is ineligible. $X$ is a covariate of interest, in this case, income.\n",
    "$ g(x)$ shows expected effect of eligibility on NET TFA for a subject whose income level is $x$.\n",
    "\n",
    "\n",
    "\n",
    "If eligibility indicator is independent of $Y(1), Y(0)$, given pre-401-k assignment characteristics $Z$, the function can expressed in terms of observed data (as opposed to hypothetical, or potential outcomes). Observed data consists of  realized NET TFA $Y = D Y(1) + (1-D) Y(0)$, eligibility indicator $D$, and covariates $Z$ which includes $X$, income. The expression for $g(x)$ is\n",
    "\n",
    "$$ g(x) = E [ Y (\\eta_0) \\mid X=x], $$\n",
    "where the transformed outcome variable is\n",
    "\n",
    "$$Y (\\eta) = \\dfrac{D}{s(Z)} \\left( Y - \\mu(1,Z) \\right) - \\dfrac{1-D}{1-s(Z)} \\left( Y - \\mu(0,Z) \\right) + \\mu(1,Z) - \\mu(0,Z),$$\n",
    "\n",
    "the probability of eligibility is\n",
    "\n",
    "$$s_0(z) = Pr (D=1 \\mid Z=z),$$\n",
    "\n",
    "the expected net financial asset given $D =d \\in \\{1,0\\}$ and $Z=z$ is\n",
    "\n",
    "$$ \\mu(d,z) = E[ Y \\mid Z=z, D=d]. $$\n",
    "\n",
    "Our goal is to estimate $g(x)$.\n",
    "\n",
    "\n",
    "In step 1, we estimate the unknown functions $s_0(z),  \\mu(1,z),  \\mu(0,z)$ and plug them into $Y (\\eta)$.\n",
    "\n",
    "\n",
    "In step 2, we approximate the function $g(x)$ by a linear combination of basis functions:\n",
    "\n",
    "$$ g(x) = p(x)' \\beta_0, $$\n",
    "\n",
    "\n",
    "where $p(x)$ is a vector of polynomials or splines and\n",
    "\n",
    "$$ \\beta_0 = (E p(X) p(X))^{-1} E p(X) Y (\\eta_0) $$\n",
    "\n",
    "is the best linear predictor. We report\n",
    "\n",
    "$$\n",
    "\\widehat{g}(x) = p(x)' \\widehat{\\beta},\n",
    "$$\n",
    "\n",
    "where $\\widehat{\\beta}$ is the ordinary least squares estimate of $\\beta_0$ defined on the random sample $(X_i, D_i, Y_i)_{i=1}^N$\n",
    "\n",
    "$$\n",
    "\t\\widehat{\\beta} :=\\left( \\dfrac{1}{N} \\sum_{i=1}^N p(X_i) p(X_i)' \\right)^{-1} \\dfrac{1}{N} \\sum_{i=1}^N  p(X_i)Y_i(\\widehat{\\eta})\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "051d70d956493feee0c6d64651c6a088724dca2a",
    "id": "Lsd0vLFOlwi4",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## load packages\n",
    "install.packages(\"foreign\")\n",
    "install.packages(\"quantreg\")\n",
    "install.packages(\"splines\")\n",
    "install.packages(\"lattice\")\n",
    "install.packages(\"Hmisc\")\n",
    "install.packages(\"fda\")\n",
    "install.packages(\"hdm\")\n",
    "install.packages(\"randomForest\")\n",
    "install.packages(\"ranger\")\n",
    "install.packages(\"sandwich\")\n",
    "install.packages(\"ggplot2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(foreign)\n",
    "library(quantreg)\n",
    "library(splines)\n",
    "library(lattice)\n",
    "library(Hmisc)\n",
    "library(fda)\n",
    "library(hdm)\n",
    "library(randomForest)\n",
    "library(ranger)\n",
    "library(sandwich)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3fqmaJFlwi6",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## 401k dataset\n",
    "data(pension)\n",
    "pension$net_tfa <- pension$net_tfa / 10000\n",
    "## covariate of interest -- log income --\n",
    "pension$inc <- log(pension$inc)\n",
    "pension <- pension[!is.na(pension$inc) & pension$inc != -Inf & pension$inc != Inf, ]\n",
    "\n",
    "\n",
    "## outcome variable -- total net financial assets\n",
    "Y <- pension$net_tfa\n",
    "## binary treatment --  indicator of 401(k) eligibility\n",
    "D <- pension$e401\n",
    "\n",
    "\n",
    "X <- pension$inc\n",
    "## target parameter is CATE = E[ Y(1) - Y(0) | X]\n",
    "\n",
    "\n",
    "## raw covariates so that Y(1) and Y(0) are independent of D given Z\n",
    "Z <- pension[, c(\n",
    "  \"age\", \"inc\", \"fsize\", \"educ\", \"male\", \"db\", \"marr\", \"twoearn\", \"pira\", \"hown\", \"hval\", \"hequity\", \"hmort\",\n",
    "  \"nohs\", \"hs\", \"smcol\"\n",
    ")]\n",
    "\n",
    "\n",
    "y_name <- \"net_tfa\"\n",
    "d_name <- \"e401\"\n",
    "form_z <- paste(\"(poly(age, 6) + poly(inc, 8) + poly(educ, 4) + poly(fsize,2) + as.factor(marr) + \",\n",
    "                \"as.factor(twoearn) + as.factor(db) + as.factor(pira) + as.factor(hown))^2\")\n",
    "cat(sprintf(\"\\n sample size is %g \\n\", length(Y)))\n",
    "cat(sprintf(\"\\n num raw covariates z is %g \\n\", dim(Z)[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMNm-HsYlwi7"
   },
   "source": [
    "In Step 1, we estimate three functions:\n",
    "\n",
    "1. probability of treatment assignment $s_0(z)$\n",
    "\n",
    "2.-3. regression functions $\\mu_0(1,z)$ and $\\mu_0(0,z)$.  \n",
    "\n",
    "We use the cross-fitting procedure with $K=2$ holds. For definition of cross-fitting with $K$ folds, check the sample splitting in ```DML2.for.PLM``` function defined in https://www.kaggle.com/victorchernozhukov/debiased-ml-for-partially-linear-model-in-r\n",
    "\n",
    "For each function, we try random forest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mug_Q4w2lwi7"
   },
   "source": [
    "First Stage: estimate $\\mu_0(1,z)$ and $\\mu_0(0,z)$ and $s_0(z)$ by lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "um5Uxua2lwi7",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "first_stage_lasso <- function(data, d_name, y_name, form_z, seed = 1) {\n",
    "  # Sample size\n",
    "  N <- dim(data)[1]\n",
    "  # Estimated regression function in control group\n",
    "  mu0_hat <- rep(1, N)\n",
    "  # Estimated regression function in treated group\n",
    "  mu1_hat <- rep(1, N)\n",
    "  # Propensity score\n",
    "  s_hat <- rep(1, N)\n",
    "  seed <- 1\n",
    "  ## define sample splitting\n",
    "  set.seed(seed)\n",
    "  inds_train <- sample(1:N, floor(N / 2))\n",
    "  inds_eval <- setdiff(1:N, inds_train)\n",
    "\n",
    "  print(\"Estimate treatment probability, first half\")\n",
    "  ## conditional probability of 401 k eligibility (i.e., propensity score) based on random forest\n",
    "  fitted_lasso_pscore <- rlassologit(as.formula(paste0(d_name, \"~\", form_z)), data = data[inds_train, ])\n",
    "\n",
    "  s_hat[inds_eval] <- predict(fitted_lasso_pscore, data[inds_eval, ], type = \"response\")\n",
    "  print(\"Estimate treatment probability, second half\")\n",
    "  fitted_lasso_pscore <- rlassologit(as.formula(paste0(d_name, \"~\", form_z)), data = data[inds_eval, ])\n",
    "  s_hat[inds_train] <- predict(fitted_lasso_pscore, data[inds_train, ], type = \"response\")\n",
    "\n",
    "\n",
    "  data1 <- data\n",
    "  data1[, d_name] <- 1\n",
    "\n",
    "  data0 <- data\n",
    "  data0[, d_name] <- 0\n",
    "\n",
    "  print(\"Estimate expectation function, first half\")\n",
    "  fitted_lasso_mu <- rlasso(as.formula(paste0(y_name, \"~\", d_name, \"+(\", form_z, \")\")), data = data[inds_train, ])\n",
    "  mu1_hat[inds_eval] <- predict(fitted_lasso_mu, data1[inds_eval, ])\n",
    "  mu0_hat[inds_eval] <- predict(fitted_lasso_mu, data0[inds_eval, ])\n",
    "\n",
    "  print(\"Estimate expectation function, second half\")\n",
    "  fitted_lasso_mu <- rlasso(as.formula(paste0(y_name, \"~\", d_name, \"+(\", form_z, \")\")), data = data[inds_eval, ])\n",
    "  mu1_hat[inds_train] <- predict(fitted_lasso_mu, data1[inds_train, ])\n",
    "  mu0_hat[inds_train] <- predict(fitted_lasso_mu, data0[inds_train, ])\n",
    "\n",
    "  return(list(\n",
    "    mu1_hat = mu1_hat,\n",
    "    mu0_hat = mu0_hat,\n",
    "    s_hat = s_hat\n",
    "  ))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCwXUQtUlwi8"
   },
   "source": [
    "First Stage: estimate $\\mu_0(1,z)$ and $\\mu_0(0,z)$ and $s_0(z)$ by random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XXWJvNPTlwi8",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "first_stage_rf <- function(Y, D, Z, seed = 1) {\n",
    "  # Sample size\n",
    "  N <- length(D)\n",
    "  # Estimated regression function in control group\n",
    "  mu0_hat <- rep(1, N)\n",
    "  # Estimated regression function in treated group\n",
    "  mu1_hat <- rep(1, N)\n",
    "  # Propensity score\n",
    "  s_hat <- rep(1, N)\n",
    "\n",
    "\n",
    "  ## define sample splitting\n",
    "  set.seed(seed)\n",
    "  inds_train <- sample(1:N, floor(N / 2))\n",
    "  inds_eval <- setdiff(1:N, inds_train)\n",
    "\n",
    "  print(\"Estimate treatment probability, first half\")\n",
    "  ## conditional probability of 401 k eligibility (i.e., propensity score) based on random forest\n",
    "  Df <- as.factor(as.character(D))\n",
    "  fitted_rf_pscore <- randomForest(Z, Df, subset = inds_train)\n",
    "  s_hat[inds_eval] <- predict(fitted_rf_pscore, Z[inds_eval, ], type = \"prob\")[, 2]\n",
    "  print(\"Estimate treatment probability, second half\")\n",
    "  fitted_rf <- randomForest(Z, Df, subset = inds_eval)\n",
    "  s_hat[inds_train] <- predict(fitted_rf_pscore, Z[inds_train, ], type = \"prob\")[, 2]\n",
    "\n",
    "  ## conditional expected net financial assets (i.e.,  regression function) based on random forest\n",
    "\n",
    "  covariates <- cbind(Z, D)\n",
    "\n",
    "  covariates1 <- cbind(Z, D = rep(1, N))\n",
    "  covariates0 <- cbind(Z, D = rep(0, N))\n",
    "\n",
    "  print(\"Estimate expectation function, first half\")\n",
    "  fitted_rf_mu <- randomForest(cbind(Z, D), Y, subset = inds_train)\n",
    "  mu1_hat[inds_eval] <- predict(fitted_rf_mu, covariates1[inds_eval, ])\n",
    "  mu0_hat[inds_eval] <- predict(fitted_rf_mu, covariates0[inds_eval, ])\n",
    "\n",
    "  print(\"Estimate expectation function, second half\")\n",
    "  fitted_rf_mu <- randomForest(cbind(Z, D), Y, subset = inds_eval)\n",
    "  mu1_hat[inds_train] <- predict(fitted_rf_mu, covariates1[inds_train, ])\n",
    "  mu0_hat[inds_train] <- predict(fitted_rf_mu, covariates0[inds_train, ])\n",
    "\n",
    "  return(list(\n",
    "    mu1_hat = mu1_hat,\n",
    "    mu0_hat = mu0_hat,\n",
    "    s_hat = s_hat\n",
    "  ))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlNaseXIlwi8"
   },
   "source": [
    "In Step 2, we approximate $Y(\\eta_0)$ by a vector of basis functions. There are two use cases:\n",
    "****\n",
    "2.A. Group Average Treatment Effect, described above\n",
    "\n",
    "\n",
    "2.B. Average Treatment Effect conditional on income value. There are three smoothing options:\n",
    "\n",
    "1. splines offered in ```least_squares_splines```\n",
    "\n",
    "2. orthogonal polynomials with the highest degree chosen by cross-validation ```least_squares_series```\n",
    "\n",
    "3. standard polynomials with the highest degree input by user ```least_squares_series_old```\n",
    "\n",
    "\n",
    "The default option is option 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lg4CWsRqlwi8"
   },
   "source": [
    "2.A. The simplest use case of Conditional Average Treatment Effect is GATE, or Group Average Treatment Effect. Partition the support of income as\n",
    "\n",
    "$$ - \\infty = \\ell_0 < \\ell_1 < \\ell_2 \\dots \\ell_K = \\infty $$\n",
    "\n",
    "define intervals $I_k = [ \\ell_{k-1}, \\ell_{k})$. Let $X$ be income covariate. For $X$, define a group indicator\n",
    "\n",
    "$$ G_k(X) = 1[X \\in I_k], $$\n",
    "\n",
    "and the vector of basis functions\n",
    "\n",
    "$$ p(X) = (G_1(X), G_2(X), \\dots, G_K(X)) $$\n",
    "\n",
    "Then, the Best Linear Predictor $\\beta_0$ vector shows the average treatment effect for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDrRceialwi9",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## estimate first stage functions by random forest\n",
    "## may take a while\n",
    "fs_hat_rf <- first_stage_rf(Y, D, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y76SLTKPlwi9",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "X <- pension$inc\n",
    "fs_hat <- fs_hat_rf\n",
    "min_cutoff <- 0.01\n",
    "# regression function\n",
    "mu1_hat <- fs_hat[[\"mu1_hat\"]]\n",
    "mu0_hat <- fs_hat[[\"mu0_hat\"]]\n",
    "# propensity score\n",
    "s_hat <- fs_hat[[\"s_hat\"]]\n",
    "s_hat <- sapply(s_hat, max, min_cutoff)\n",
    "\n",
    "### Construct Orthogonal Signal\n",
    "RobustSignal <- (Y - mu1_hat) * D / s_hat - (Y - mu0_hat) * (1 - D) / (1 - s_hat) + mu1_hat - mu0_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nODBERqdlwi9",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "qtmax <- function(C, S = 10000, alpha) {\n",
    "  p <- nrow(C)\n",
    "  tmaxs <- apply(abs(matrix(rnorm(p * S), nrow = p, ncol = S)), 2, max)\n",
    "  return(quantile(tmaxs, 1 - alpha))\n",
    "}\n",
    "\n",
    "# This function computes the square root of a symmetric matrix using the spectral decomposition;\n",
    "\n",
    "group_average_treatment_effect <- function(X, Y, max_grid = 5, alpha = 0.05, B = 10000) {\n",
    "  grid <- quantile(X, probs = c((0:max_grid) / max_grid))\n",
    "  Xraw <- matrix(NA, nrow = length(Y), ncol = length(grid) - 1)\n",
    "\n",
    "  for (k in 2:((length(grid)))) {\n",
    "    Xraw[, k - 1] <- sapply(X, function(x) ifelse(x >= grid[k - 1] & x < grid[k], 1, 0))\n",
    "  }\n",
    "  k <- length(grid)\n",
    "  Xraw[, k - 1] <- sapply(X, function(x) ifelse(x >= grid[k - 1] & x <= grid[k], 1, 0))\n",
    "\n",
    "  ols_fit <- lm(Y ~ Xraw - 1)\n",
    "  coefs <- coef(ols_fit)\n",
    "  vars <- names(coefs)\n",
    "  hcv_coefs <- vcovHC(ols_fit, type = \"HC\")\n",
    "  coefs_se <- sqrt(diag(hcv_coefs)) # White std errors\n",
    "  ## this is an identity matrix\n",
    "  ## qtmax is simplified\n",
    "  c_coefs <- (diag(1 / sqrt(diag(hcv_coefs)))) %*% hcv_coefs %*% (diag(1 / sqrt(diag(hcv_coefs))))\n",
    "\n",
    "\n",
    "  tes <- coefs\n",
    "  tes_se <- coefs_se\n",
    "  tes_cor <- c_coefs\n",
    "  crit_val <- qtmax(tes_cor, B, alpha)\n",
    "\n",
    "  tes_ucb <- tes + crit_val * tes_se\n",
    "  tes_lcb <- tes - crit_val * tes_se\n",
    "\n",
    "  tes_uci <- tes + qnorm(1 - alpha / 2) * tes_se\n",
    "  tes_lci <- tes + qnorm(alpha / 2) * tes_se\n",
    "\n",
    "\n",
    "  return(list(\n",
    "    beta_hat = coefs, ghat_lower_point = tes_lci, ghat_upper_point = tes_uci,\n",
    "    ghat_lower = tes_lcb, ghat_upper = tes_ucb, crit_val = crit_val\n",
    "  ))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "anNpVKgnlwi9",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "res <- group_average_treatment_effect(X = X, Y = RobustSignal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sdpo7pwMlwi9",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## this code is taken from L1 14.382 taught at MIT\n",
    "## author: Mert Demirer\n",
    "options(repr.plot.width = 10, repr.plot.height = 8)\n",
    "\n",
    "tes <- res$beta_hat\n",
    "tes_lci <- res$ghat_lower_point\n",
    "tes_uci <- res$ghat_upper_point\n",
    "\n",
    "tes_lcb <- res$ghat_lower\n",
    "tes_ucb <- res$ghat_upper\n",
    "tes_lev <- c(\"0%-20%\", \"20%-40%\", \"40%-60%\", \"60%-80%\", \"80%-100%\")\n",
    "\n",
    "plot(c(1, 5), las = 2, xlim = c(0.6, 5.4), ylim = c(.05, 2.09),  type = \"n\", xlab = \"Income group\",\n",
    "     ylab = \"Average Effect on NET TFA (per 10 K)\",\n",
    "     main = \"Group Average Treatment Effects on NET TFA\",\n",
    "     xaxt = \"n\")\n",
    "axis(1, at = 1:5, labels = tes_lev)\n",
    "for (i in 1:5) {\n",
    "  rect(i - 0.2, tes_lci[i], i + 0.2,  tes_uci[i], col = NA,  border = \"red\", lwd = 3)\n",
    "  rect(i - 0.2, tes_lcb[i], i + 0.2, tes_ucb[i], col = NA,  border = 4, lwd = 3)\n",
    "  segments(i - 0.2, tes[i], i + 0.2, tes[i], lwd = 5)\n",
    "}\n",
    "abline(h = 0)\n",
    "\n",
    "legend(2.5, 2.0,\n",
    "       c(\"Regression Estimate\", \"95% Simultaneous Confidence Interval\", \"95% Pointwise Confidence Interval\"),\n",
    "       col = c(1, 4, 2), lwd = c(4, 3, 3), horiz = FALSE, bty = \"n\", cex = 0.8)\n",
    "\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_BXi61OQlwi9",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "least_squares_splines <- function(X, Y, max_knot = 9, norder, nderiv, ...) {\n",
    "  ## Create technical regressors\n",
    "  cv_bsp <- rep(0, max_knot - 1)\n",
    "  for (knot in 2:max_knot) {\n",
    "    breaks <- quantile(X, c(0:knot) / knot)\n",
    "    formula.bsp <- Y ~ bsplineS(X, breaks = breaks, norder = norder, nderiv = nderiv)[, -1]\n",
    "    fit <- lm(formula.bsp)\n",
    "    cv_bsp[knot - 1] <- sum((fit$res / (1 - hatvalues(fit)))^2)\n",
    "  }\n",
    "  ## Number of knots chosen by cross-validation\n",
    "  cv_knot <- which.min(cv_bsp) + 1\n",
    "  breaks <- quantile(X, c(0:cv_knot) / cv_knot)\n",
    "  formula.bsp <- Y ~ bsplineS(X, breaks = breaks, norder = norder, nderiv = 0)[, -1]\n",
    "  fit <- lm(formula.bsp)\n",
    "\n",
    "  return(list(cv_knot = cv_knot, fit = fit))\n",
    "}\n",
    "\n",
    "\n",
    "least_squares_series <- function(X, Y, max_degree, ...) {\n",
    "  cv_pol <- rep(0, max_degree)\n",
    "  for (degree in 1:max_degree) {\n",
    "    formula.pol <- Y ~ poly(X, degree)\n",
    "    fit <- lm(formula.pol)\n",
    "    cv_pol[degree] <- sum((fit$res / (1 - hatvalues(fit)))^2)\n",
    "  }\n",
    "  ## Number of knots chosen by cross-validation\n",
    "  cv_degree <- which.min(cv_pol)\n",
    "  ## Estimate coefficients\n",
    "  formula.pol <- Y ~ poly(X, cv_degree)\n",
    "  fit <- lm(formula.pol)\n",
    "\n",
    "  return(list(fit = fit, cv_degree = cv_degree))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvxphkMUlwi-",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "msqrt <- function(C) {\n",
    "  Ceig <- eigen(C)\n",
    "  return(Ceig$vectors %*% diag(sqrt(Ceig$values)) %*% solve(Ceig$vectors))\n",
    "}\n",
    "\n",
    "tboot <- function(regressors_grid, omega_hat, alpha, B = 10000) {\n",
    "  numerator_grid <- regressors_grid %*% msqrt(omega_hat)\n",
    "  denominator_grid <- sqrt(diag(regressors_grid %*% omega_hat %*% t(regressors_grid)))\n",
    "\n",
    "  norm_numerator_grid <- numerator_grid\n",
    "  for (k in seq_len(dim(numerator_grid)[1])) {\n",
    "    norm_numerator_grid[k, ] <- numerator_grid[k, ] / denominator_grid[k]\n",
    "  }\n",
    "\n",
    "  tmaxs <- apply(abs(norm_numerator_grid %*% matrix(rnorm(dim(numerator_grid)[2] * B),\n",
    "                                                    nrow = dim(numerator_grid)[2], ncol = B)), 2, max)\n",
    "  return(quantile(tmaxs, 1 - alpha))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nupH8ItWlwi-",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "second_stage <- function(fs_hat, Y, D, X, max_degree = 3, norder = 4, nderiv = 0,\n",
    "                         ss_method = \"poly\", min_cutoff = 0.01, alpha = 0.05, eps = 0.1, ...) {\n",
    "  x_grid <- seq(min(X), max(X), eps)\n",
    "  mu1_hat <- fs_hat[[\"mu1_hat\"]]\n",
    "  mu0_hat <- fs_hat[[\"mu0_hat\"]]\n",
    "  # propensity score\n",
    "  s_hat <- fs_hat[[\"s_hat\"]]\n",
    "  s_hat <- sapply(s_hat, max, min_cutoff)\n",
    "  ### Construct Orthogonal Signal\n",
    "\n",
    "  RobustSignal <- (Y - mu1_hat) * D / s_hat - (Y - mu0_hat) * (1 - D) / (1 - s_hat) + mu1_hat - mu0_hat\n",
    "\n",
    "  # Estimate the target function using least squares series\n",
    "  if (ss_method == \"ortho_poly\") {\n",
    "    res <- least_squares_series(X = X, Y = RobustSignal, eps = 0.1, max_degree = max_degree)\n",
    "    fit <- res$fit\n",
    "    cv_degree <- res$cv_degree\n",
    "    regressors_grid <- cbind(rep(1, length(x_grid)), poly(x_grid, cv_degree))\n",
    "  }\n",
    "  if (ss_method == \"splines\") {\n",
    "    res <- least_squares_splines(X = X, Y = RobustSignal, eps = 0.1, norder = norder, nderiv = nderiv)\n",
    "    fit <- res$fit\n",
    "    cv_knot <- res$cv_knot\n",
    "    breaks <- quantile(X, c(0:cv_knot) / cv_knot)\n",
    "    regressors_grid <- cbind(rep(1, length(x_grid)),\n",
    "                             bsplineS(x_grid, breaks = breaks, norder = norder, nderiv = nderiv)[, -1])\n",
    "    degree <- cv_knot\n",
    "  }\n",
    "\n",
    "  g_hat <- regressors_grid %*% coef(fit)\n",
    "\n",
    "  hcv_coefs <- vcovHC(fit, type = \"HC\")\n",
    "  standard_error <- sqrt(diag(regressors_grid %*% hcv_coefs %*% t(regressors_grid)))\n",
    "\n",
    "  ### Lower Pointwise CI\n",
    "  ghat_lower_point <- g_hat + qnorm(alpha / 2) * standard_error\n",
    "  ### Upper Pointwise CI\n",
    "  ghat_upper_point <- g_hat + qnorm(1 - alpha / 2) * standard_error\n",
    "\n",
    "  max_tstat <- tboot(regressors_grid = regressors_grid, omega_hat = hcv_coefs, alpha = alpha)\n",
    "\n",
    "  ## Lower Uniform CI\n",
    "  ghat_lower <- g_hat - max_tstat * standard_error\n",
    "  ## Upper Uniform CI\n",
    "  ghat_upper <- g_hat + max_tstat * standard_error\n",
    "  return(list(\n",
    "    ghat_lower = ghat_lower, g_hat = g_hat, ghat_upper = ghat_upper, fit = fit,\n",
    "    ghat_lower_point = ghat_lower_point, ghat_upper_point = ghat_upper_point, x_grid = x_grid\n",
    "  ))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NB10aQcPlwi-",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "make_plot <- function(res, lowy, highy, degree, ss_method = \"series\", uniform = TRUE, ...) {\n",
    "  title <- paste0(\"Effect of 401(k) on Net TFA, \", ss_method)\n",
    "  x_grid <- res$x_grid\n",
    "  len <- length(x_grid)\n",
    "\n",
    "\n",
    "  if (uniform) {\n",
    "    group <- c(rep(\"UCI\", len), rep(\"PCI\", len), rep(\"Estimate\", len), rep(\"PCIL\", len), rep(\"UCIL\", len))\n",
    "    group_type <- c(rep(\"CI\", len), rep(\"CI\", len), rep(\"Estimate\", len), rep(\"CI\", len), rep(\"CI\", len))\n",
    "    group_ci_type <- c(rep(\"Uniform\", len), rep(\"Point\", len),\n",
    "                       rep(\"Uniform\", len), rep(\"Point\", len), rep(\"Uniform\", len))\n",
    "\n",
    "    df <- data.frame(income = rep(x_grid, 5),\n",
    "                     outcome = c(res$ghat_lower, res$ghat_lower_point,\n",
    "                                 res$g_hat, res$ghat_upper_point, res$ghat_upper),\n",
    "                     group = group, group_col = group_type, group_line = group_ci_type)\n",
    "    p <- ggplot(data = df) +\n",
    "      aes(x = exp(income), y = outcome, colour = group) +\n",
    "      theme_bw() +\n",
    "      xlab(\"Income\") +\n",
    "      ylab(\"Net TFA, (thousand dollars)\") +\n",
    "      scale_colour_manual(values = c(\"black\", \"blue\", \"blue\", \"blue\", \"blue\")) +\n",
    "      theme(plot.title = element_text(hjust = 0.5), text = element_text(size = 20, family = \"serif\")) +\n",
    "      theme(legend.title = element_blank()) +\n",
    "      theme(legend.position = \"none\") +\n",
    "      ylim(low = lowy, high = highy) +\n",
    "      geom_line(aes(linetype = group_line), size = 1.5) +\n",
    "      scale_linetype_manual(values = c(\"dashed\", \"solid\")) +\n",
    "      ggtitle(title)\n",
    "  }\n",
    "\n",
    "  if (!uniform) {\n",
    "    group <- c(rep(\"PCI\", len), rep(\"Estimate\", len), rep(\"PCIL\", len))\n",
    "    group_type <- c(rep(\"CI\", len), rep(\"Estimate\", len), rep(\"CI\", len))\n",
    "    group_ci_type <- c(rep(\"Point\", len), rep(\"Uniform\", len), rep(\"Point\", len))\n",
    "\n",
    "    df <- data.frame(income = rep(x_grid, 3),\n",
    "                     outcome = c(res$ghat_lower_point, res$g_hat, res$ghat_upper_point),\n",
    "                     group = group, group_col = group_type, group_line = group_ci_type)\n",
    "\n",
    "    p <- ggplot(data = df) +\n",
    "      aes(x = exp(income), y = outcome, colour = group) +\n",
    "      theme_bw() +\n",
    "      xlab(\"Income\") +\n",
    "      ylab(\"Net TFA, (thousand dollars)\") +\n",
    "      scale_colour_manual(values = c(\"black\", \"blue\", \"blue\", \"blue\", \"blue\")) +\n",
    "      theme(plot.title = element_text(hjust = 0.5), text = element_text(size = 20, family = \"serif\")) +\n",
    "      theme(legend.title = element_blank()) +\n",
    "      theme(legend.position = \"none\") +\n",
    "      ylim(low = lowy, high = highy) +\n",
    "      geom_line(aes(linetype = group_line), size = 1.5) +\n",
    "      scale_linetype_manual(values = c(\"dashed\", \"solid\")) +\n",
    "      ggtitle(title)\n",
    "  }\n",
    "\n",
    "  return(p)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_cHQnAblwi-",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "res_ortho_rf_splines <- second_stage(fs_hat = fs_hat_rf, X = X, D = D, Y = Y,\n",
    "                                     ss_method = \"splines\", max_degree = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AGOMgvgglwi-",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "res_ortho_rf_ortho_poly <- second_stage(fs_hat = fs_hat_rf, X = X, D = D, Y = Y,\n",
    "                                        ss_method = \"ortho_poly\", max_degree = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXpt7WdKlwi-"
   },
   "source": [
    "plot findings\n",
    "\n",
    "-- black solid line shows estimated function $p(x)' \\widehat{\\beta}$\n",
    "\n",
    "-- blue dashed lines show pointwise confidence bands for this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UfwShWdUlwi_",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "p <- make_plot(res_ortho_rf_ortho_poly, ss_method = \"ortho_poly\", uniform = FALSE, lowy = -10, highy = 20)\n",
    "options(repr.plot.width = 15, repr.plot.height = 10)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nH5ZbKG0lwi_"
   },
   "source": [
    "plot findings:\n",
    "\n",
    "-- black solid line shows estimated function $p(x)' \\widehat{\\beta}$\n",
    "\n",
    "-- blue dashed lines show pointwise confidence bands for this function. I.e., for each fixed point $x_0$, i.e., $x_0=1$, they cover $p(x_0)'\\beta_0$ with probability 0.95\n",
    "\n",
    "-- blue solid lines show  uniform confidence bands for this function. I.e.,  they cover the whole function $x \\rightarrow p(x)'\\beta_0$ with probability 0.95 on some compact range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDcX_Pkylwi_",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "p <- make_plot(res_ortho_rf_ortho_poly, ss_method = \"ortho polynomials\", uniform = TRUE, lowy = -10, highy = 25)\n",
    "options(repr.plot.width = 15, repr.plot.height = 10)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RRrnhWU0lwi_",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "p <- make_plot(res_ortho_rf_splines, ss_method = \"splines\", uniform = FALSE, lowy = -15, highy = 10)\n",
    "options(repr.plot.width = 15, repr.plot.height = 10)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ShL8EFdTlwi_",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "p <- make_plot(res_ortho_rf_splines, ss_method = \"splines\", uniform = TRUE, lowy = -20, highy = 20)\n",
    "options(repr.plot.width = 15, repr.plot.height = 10)\n",
    "print(p)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
