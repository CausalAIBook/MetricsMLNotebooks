{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install econml\n",
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.special\n",
    "from sklearn.linear_model import LassoCV, LinearRegression, ElasticNetCV\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.base import clone\n",
    "import joblib\n",
    "from statsmodels.api import OLS\n",
    "from sklearn.model_selection import StratifiedGroupKFold, GroupKFold, KFold, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [................................................................................] 5006 / 5006"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'myxgb.py'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wget\n",
    "import os\n",
    "\n",
    "if os.path.exists('datasets.py'):\n",
    "    os.remove('datasets.py')\n",
    "wget.download('https://raw.githubusercontent.com/CausalAIBook/MetricsMLNotebooks/main/T/datasets.py')\n",
    "\n",
    "if os.path.exists('myxgb.py'):\n",
    "    os.remove('myxgb.py')\n",
    "wget.download('https://raw.githubusercontent.com/CausalAIBook/MetricsMLNotebooks/main/T/myxgb.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the High Level Parameters for the Notebook\n",
    "\n",
    "The 401k dataset is downloaded from the source by the code and no need to further download anything:\n",
    "https://raw.githubusercontent.com/CausalAIBook/MetricsMLNotebooks/main/data/401k.csv\n",
    "\n",
    "The welfare dataset is downloaded from the source by the code and no need to further download anything:\n",
    "https://github.com/gsbDBI/ExperimentData/blob/master/Welfare/ProcessedData/welfarenolabel3.csv \n",
    "\n",
    "It is drawn from the analysis in this paper: [Green and Kern, 2012, Modeling Heterogeneous Treatment Effects in Survey Experiments with Bayesian Additive Regression Trees](https://github.com/gsbDBI/ExperimentData/blob/master/Welfare/Green%20and%20Kern%20BART.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'welfare'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == '401k':\n",
    "    verbose = 0 # verbosity of auto-ml\n",
    "    n_splits = 5 # cross-fitting and cross-validation splits\n",
    "    cfit = False\n",
    "    data = '401k' # which dataset, one of {'401k', 'criteo', 'welfare', 'poverty', 'star'}\n",
    "    plot = True # whether to plot results\n",
    "    xfeat = 'inc' # feature to use as x axis in plotting, e.g. for criteo 'f1', for 401k 'inc', for welfare 'polviews'\n",
    "    # Formula for the BLP of CATE regression.\n",
    "    blp_formula = 'np.log(inc)' # e.g. 'f1' for criteo, np.log(inc)' for 401k, 'C(polviews)' for the welfare case.\n",
    "    blp_formula_short = 'log(inc)'\n",
    "    blp_formula2 = 'np.log(inc) + np.power(np.log(inc), 2) + np.power(np.log(inc), 3) + np.power(np.log(inc), 4)'\n",
    "    blp_formula2_short = 'poly(log(inc), 4)'\n",
    "    hetero_feats = 'all' # list of subset of features to be used for CATE model or the string 'all' for everything\n",
    "    cov_clip = .01 # clipping of treatment variance p(x)*(1-p(x)), whenever used in inverse propensities\n",
    "    binary_y = False\n",
    "    random_seed = 1\n",
    "    # treatment policy to evaluate\n",
    "    policy = lambda x: x['inc'] > 10000\n",
    "    # cost of treatment when performing optimal policy learning, can also be viewed as \"threshold for treatment\"\n",
    "    treatment_cost = 0.0\n",
    "\n",
    "    ## For semi-synthetic data generation\n",
    "    semi_synth = False # Whether true outcome y should be replaced by a fake outcome from a known CEF\n",
    "    simple_synth = True # Whether the true CEF of the fake y should be simple or fitted from data\n",
    "    max_depth = 2 # max depth of random forest during for semi-synthetic model fitting\n",
    "    scale = .2 # magnitude of noise in semi-synthetic data\n",
    "    def simple_true_cef(D, X): # simple CEF of the outcome for semi-synthetic data\n",
    "        return .5 * np.array(X)[:, 1] * D + np.array(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'welfare':\n",
    "    verbose = 0 # verbosity of auto-ml\n",
    "    n_splits = 5 # cross-fitting and cross-validation splits\n",
    "    cfit = True\n",
    "    data = 'welfare' # which dataset, one of {'401k', 'criteo', 'welfare', 'poverty', 'star'}\n",
    "    plot = True # whether to plot results\n",
    "    xfeat = 'polviews' # feature to use as x axis in plotting, e.g. for criteo 'f1', for 401k 'inc', for welfare 'polviews'\n",
    "    # Formula for the BLP of CATE regression.\n",
    "    blp_formula = 'C(polviews)' # e.g. 'f1' for criteo, np.log(inc)' for 401k, 'C(polviews)' for the welfare case.\n",
    "    blp_formula_short = 'C(polviews)'\n",
    "    blp_formula2 = 'polviews'\n",
    "    blp_formula2_short = 'polviews'\n",
    "    hetero_feats = 'all' # list of subset of features to be used for CATE model or the string 'all' for everything\n",
    "    cov_clip = .01 # clipping of treatment variance p(x)*(1-p(x)), whenever used in inverse propensities\n",
    "    binary_y = True\n",
    "    random_seed = 1\n",
    "    # treatment policy to evaluate\n",
    "    policy = lambda x: x['polviews'] > 3\n",
    "    # cost of treatment when performing optimal policy learning, can also be viewed as \"threshold for treatment\"\n",
    "    treatment_cost = -.3\n",
    "\n",
    "    ## For semi-synthetic data generation\n",
    "    semi_synth = False # Whether true outcome y should be replaced by a fake outcome from a known CEF\n",
    "    simple_synth = True # Whether the true CEF of the fake y should be simple or fitted from data\n",
    "    max_depth = 2 # max depth of random forest during for semi-synthetic model fitting\n",
    "    scale = .2 # magnitude of noise in semi-synthetic data\n",
    "    def simple_true_cef(D, X): # simple CEF of the outcome for semi-synthetic data\n",
    "        return .5 * np.array(X)[:, 1] * D + np.array(X)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching and Constructing the Dataset\n",
    "\n",
    "The data generator also allows for semi-synthetic data generation where the ground truth CATE is known, which can be used for evaluation of different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import fetch_data_generator\n",
    "\n",
    "get_data, abtest, true_cef, true_cate = fetch_data_generator(data=data, semi_synth=semi_synth,\n",
    "                                                             simple_synth=simple_synth,\n",
    "                                                             scale=scale, true_f=simple_true_cef,\n",
    "                                                             max_depth=max_depth)\n",
    "X, D, y, groups = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "if semi_synth:\n",
    "    true_ate = np.mean(true_cate(X))\n",
    "    print(f'True ATE: {true_ate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(cate, preds):\n",
    "    return np.sqrt(np.mean((cate - preds)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "We now have our data $X$, $D$, $y$, of controls, treatments and outcomes. In some datasets, we also have \"groups\", also known as \"clusters\". These are group ids, that define a group of samples that are believed to be correlated through unobesrved factors. For instance, in randomized experiments when a whole class is being treated and we have data at the student level, the students in a class constitute a cluster, as their outcome variables are most probably correlated. In such settings, it is helpful to account for the cluster correlations when calculating confidence intervals and when performing sample splitting for either cross-validation or for nuisance estimation.\n",
    "\n",
    "We will be assuming throughout that conditional ignorability is satisfied if we control for all the variables $X$, i.e. the potential outcomes $Y(1), Y(0)$ satisfy\n",
    "\\begin{align}\n",
    "Y(1), Y(0) ~\\perp\\hspace{-1em}\\perp~D \\mid X\n",
    "\\end{align}\n",
    "Equivalently, we assume that the DAG the corresponds to our setting satisfies that $X$ is a valid adjustment set between $D$ and $Y$, i.e. it blocks all backdoor paths in the DAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hrs1</th>\n",
       "      <th>income</th>\n",
       "      <th>rincome</th>\n",
       "      <th>age</th>\n",
       "      <th>polviews</th>\n",
       "      <th>educ</th>\n",
       "      <th>earnrs</th>\n",
       "      <th>sibs</th>\n",
       "      <th>childs</th>\n",
       "      <th>occ80</th>\n",
       "      <th>...</th>\n",
       "      <th>reg16</th>\n",
       "      <th>family16</th>\n",
       "      <th>parborn</th>\n",
       "      <th>maeduc</th>\n",
       "      <th>degree</th>\n",
       "      <th>hompop</th>\n",
       "      <th>babies</th>\n",
       "      <th>preteen</th>\n",
       "      <th>teens</th>\n",
       "      <th>adults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12907.000000</td>\n",
       "      <td>12907.000000</td>\n",
       "      <td>12907.000000</td>\n",
       "      <td>12907.000000</td>\n",
       "      <td>12907.000000</td>\n",
       "      <td>12907.000000</td>\n",
       "      <td>12907.000000</td>\n",
       "      <td>12907.000000</td>\n",
       "      <td>12907.000000</td>\n",
       "      <td>12907.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12907.000000</td>\n",
       "      <td>12907.000000</td>\n",
       "      <td>12907.000000</td>\n",
       "      <td>12907.000000</td>\n",
       "      <td>12907.000000</td>\n",
       "      <td>12907.000000</td>\n",
       "      <td>12907.000000</td>\n",
       "      <td>12907.000000</td>\n",
       "      <td>12907.000000</td>\n",
       "      <td>12907.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>42.260324</td>\n",
       "      <td>11.305183</td>\n",
       "      <td>10.223367</td>\n",
       "      <td>40.573952</td>\n",
       "      <td>4.083443</td>\n",
       "      <td>14.026497</td>\n",
       "      <td>1.745177</td>\n",
       "      <td>3.426823</td>\n",
       "      <td>1.569613</td>\n",
       "      <td>332.056016</td>\n",
       "      <td>...</td>\n",
       "      <td>4.417758</td>\n",
       "      <td>1.824669</td>\n",
       "      <td>0.886263</td>\n",
       "      <td>11.745874</td>\n",
       "      <td>1.758736</td>\n",
       "      <td>2.645619</td>\n",
       "      <td>0.227628</td>\n",
       "      <td>0.303479</td>\n",
       "      <td>0.216782</td>\n",
       "      <td>1.893004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.018162</td>\n",
       "      <td>1.635527</td>\n",
       "      <td>2.744435</td>\n",
       "      <td>12.179377</td>\n",
       "      <td>1.376485</td>\n",
       "      <td>2.722665</td>\n",
       "      <td>0.830837</td>\n",
       "      <td>2.918114</td>\n",
       "      <td>1.482378</td>\n",
       "      <td>242.739687</td>\n",
       "      <td>...</td>\n",
       "      <td>2.619726</td>\n",
       "      <td>1.662529</td>\n",
       "      <td>2.418884</td>\n",
       "      <td>3.313779</td>\n",
       "      <td>1.177910</td>\n",
       "      <td>1.399372</td>\n",
       "      <td>0.546265</td>\n",
       "      <td>0.656729</td>\n",
       "      <td>0.527373</td>\n",
       "      <td>0.774679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>305.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>89.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               hrs1        income       rincome           age      polviews  \\\n",
       "count  12907.000000  12907.000000  12907.000000  12907.000000  12907.000000   \n",
       "mean      42.260324     11.305183     10.223367     40.573952      4.083443   \n",
       "std       14.018162      1.635527      2.744435     12.179377      1.376485   \n",
       "min        0.000000      1.000000      1.000000     18.000000      1.000000   \n",
       "25%       38.000000     12.000000      9.000000     31.000000      3.000000   \n",
       "50%       40.000000     12.000000     12.000000     40.000000      4.000000   \n",
       "75%       50.000000     12.000000     12.000000     49.000000      5.000000   \n",
       "max       89.000000     12.000000     12.000000     88.000000      7.000000   \n",
       "\n",
       "               educ        earnrs          sibs        childs         occ80  \\\n",
       "count  12907.000000  12907.000000  12907.000000  12907.000000  12907.000000   \n",
       "mean      14.026497      1.745177      3.426823      1.569613    332.056016   \n",
       "std        2.722665      0.830837      2.918114      1.482378    242.739687   \n",
       "min        0.000000      0.000000      0.000000      0.000000      4.000000   \n",
       "25%       12.000000      1.000000      2.000000      0.000000    156.000000   \n",
       "50%       14.000000      2.000000      3.000000      2.000000    305.000000   \n",
       "75%       16.000000      2.000000      4.000000      2.000000    458.000000   \n",
       "max       20.000000      8.000000     37.000000      8.000000    889.000000   \n",
       "\n",
       "       ...         reg16      family16       parborn        maeduc  \\\n",
       "count  ...  12907.000000  12907.000000  12907.000000  12907.000000   \n",
       "mean   ...      4.417758      1.824669      0.886263     11.745874   \n",
       "std    ...      2.619726      1.662529      2.418884      3.313779   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      2.000000      1.000000      0.000000     11.000000   \n",
       "50%    ...      4.000000      1.000000      0.000000     12.000000   \n",
       "75%    ...      6.500000      1.000000      0.000000     13.000000   \n",
       "max    ...      9.000000      8.000000      8.000000     20.000000   \n",
       "\n",
       "             degree        hompop        babies       preteen         teens  \\\n",
       "count  12907.000000  12907.000000  12907.000000  12907.000000  12907.000000   \n",
       "mean       1.758736      2.645619      0.227628      0.303479      0.216782   \n",
       "std        1.177910      1.399372      0.546265      0.656729      0.527373   \n",
       "min        0.000000      1.000000      0.000000      0.000000      0.000000   \n",
       "25%        1.000000      2.000000      0.000000      0.000000      0.000000   \n",
       "50%        1.000000      2.000000      0.000000      0.000000      0.000000   \n",
       "75%        3.000000      4.000000      0.000000      0.000000      0.000000   \n",
       "max        4.000000     11.000000      4.000000      5.000000      4.000000   \n",
       "\n",
       "             adults  \n",
       "count  12907.000000  \n",
       "mean       1.893004  \n",
       "std        0.774679  \n",
       "min        1.000000  \n",
       "25%        1.000000  \n",
       "50%        2.000000  \n",
       "75%        2.000000  \n",
       "max        8.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(D)\n",
    "plt.title('Treatment')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(y)\n",
    "plt.title('Outcome')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.164</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.164</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2476.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 14 Feb 2024</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:31:13</td>     <th>  Log-Likelihood:    </th> <td> -6969.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 12907</td>      <th>  AIC:               </th> <td>1.394e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 12905</td>      <th>  BIC:               </th> <td>1.396e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC1</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.4798</td> <td>    0.006</td> <td>   76.111</td> <td> 0.000</td> <td>    0.467</td> <td>    0.492</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.3681</td> <td>    0.007</td> <td>  -49.761</td> <td> 0.000</td> <td>   -0.383</td> <td>   -0.354</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1655.598</td> <th>  Durbin-Watson:     </th> <td>   1.990</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1148.663</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.621</td>  <th>  Prob(JB):          </th> <td>3.72e-250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 2.230</td>  <th>  Cond. No.          </th> <td>    2.65</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC1)"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.164   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.164   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     2476.   \\\\\n",
       "\\textbf{Date:}             & Wed, 14 Feb 2024 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}             &     11:31:13     & \\textbf{  Log-Likelihood:    } &   -6969.7   \\\\\n",
       "\\textbf{No. Observations:} &       12907      & \\textbf{  AIC:               } & 1.394e+04   \\\\\n",
       "\\textbf{Df Residuals:}     &       12905      & \\textbf{  BIC:               } & 1.396e+04   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &       HC1        & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       0.4798  &        0.006     &    76.111  &         0.000        &        0.467    &        0.492     \\\\\n",
       "\\textbf{x1}    &      -0.3681  &        0.007     &   -49.761  &         0.000        &       -0.383    &       -0.354     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 1655.598 & \\textbf{  Durbin-Watson:     } &     1.990  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } &  1148.663  \\\\\n",
       "\\textbf{Skew:}          &   0.621  & \\textbf{  Prob(JB):          } & 3.72e-250  \\\\\n",
       "\\textbf{Kurtosis:}      &   2.230  & \\textbf{  Cond. No.          } &      2.65  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors are heteroscedasticity robust (HC1)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.164\n",
       "Model:                            OLS   Adj. R-squared:                  0.164\n",
       "Method:                 Least Squares   F-statistic:                     2476.\n",
       "Date:                Wed, 14 Feb 2024   Prob (F-statistic):               0.00\n",
       "Time:                        11:31:13   Log-Likelihood:                -6969.7\n",
       "No. Observations:               12907   AIC:                         1.394e+04\n",
       "Df Residuals:                   12905   BIC:                         1.396e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:                  HC1                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.4798      0.006     76.111      0.000       0.467       0.492\n",
       "x1            -0.3681      0.007    -49.761      0.000      -0.383      -0.354\n",
       "==============================================================================\n",
       "Omnibus:                     1655.598   Durbin-Watson:                   1.990\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1148.663\n",
       "Skew:                           0.621   Prob(JB):                    3.72e-250\n",
       "Kurtosis:                       2.230   Cond. No.                         2.65\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC1)\n",
       "\"\"\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple two means estimate which would be wrong unless an randomized trial\n",
    "OLS(y, np.hstack([np.ones((D.shape[0], 1)), D.reshape(-1, 1)])).fit(cov_type='HC1').summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuisance Model Selection\n",
    "\n",
    "Using the training data we will select the best model for each of the nuisance models that arise in meta learner CATE approaches. They five models correspond to the following five predictive problems:\n",
    "\\begin{align}\n",
    "\\text{model_reg} ~\\rightarrow~& g(d, x) := E[Y\\mid D=d, X=x]\\\\\n",
    "\\text{model_y} ~\\rightarrow~& q(x) := E[Y\\mid X=x]\\\\\n",
    "\\text{model_t} ~\\rightarrow~& p(x) := E[D\\mid X=x] = \\Pr(D=1\\mid X=x)\\\\\n",
    "\\text{model_reg_zero} ~\\rightarrow~& g_0(x) := E[Y\\mid D=0, X=x]\\\\\n",
    "\\text{model_reg_one} ~\\rightarrow~& g_1(x) := E[Y\\mid D=1, X=x]\\\\\n",
    "\\end{align}\n",
    "We will select the best hyperparameters/model type for each predictive problem using cross-validation, where the splits are also stratified by the treatment (so that we have balanced split of the treatment groups across folds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myxgb import xgb_reg, xgb_clf\n",
    "\n",
    "auto_reg = lambda: xgb_reg(random_seed)\n",
    "auto_clf = lambda: xgb_clf(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_y = auto_reg\n",
    "model_reg_zero = auto_reg\n",
    "model_reg_one = auto_reg\n",
    "model_t = auto_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now also evaluate the performance of the selected models in terms of R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if groups is None:\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "else:\n",
    "    cv = GroupKFold(n_splits=n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_reg = np.mean(cross_val_score(model_y(), X, y, groups=groups, cv=cv, scoring='r2'))\n",
    "print(f'model_y: {score_reg:.3f}')\n",
    "score_reg = np.mean(cross_val_score(model_t(), X, D, groups=groups, cv=cv, scoring='r2'))\n",
    "print(f'model_t: {score_reg:.3f}')\n",
    "if groups is None:\n",
    "    score_reg = np.mean(cross_val_score(model_reg_zero(), X[D==0], y[D==0], groups=None, cv=cv, scoring='r2'))\n",
    "    print(f'model_reg_zero: {score_reg:.3f}')\n",
    "    score_reg = np.mean(cross_val_score(model_reg_one(), X[D==1], y[D==1], groups=None, cv=cv, scoring='r2'))\n",
    "    print(f'model_reg_one: {score_reg:.3f}')\n",
    "else:\n",
    "    score_reg = np.mean(cross_val_score(model_reg_zero(), X[D==0], y[D==0], groups=groups[D==0], cv=cv, scoring='r2'))\n",
    "    print(f'model_reg_zero: {score_reg:.3f}')\n",
    "    score_reg = np.mean(cross_val_score(model_reg_one(), X[D==1], y[D==1], groups=groups[D==1], cv=cv, scoring='r2'))\n",
    "    print(f'model_reg_one: {score_reg:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuisance Cross-Fitted Estimation and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After selecting the hyper-parameters for each of the nuisance models we perform cross-fitting to get out-of-fold predictions from each of these nuisance models. At the end of this process, we will have for each sample $i$, the following out-of-fold nuisance values:\n",
    "\\begin{align}\n",
    "\\text{reg_preds} \\rightarrow~& \\hat{g}(D_i, X_i) &\n",
    "\\text{reg_one_preds} \\rightarrow~& \\hat{g}(1, X_i) &\n",
    "\\text{reg_zero_preds} \\rightarrow~& \\hat{g}(0, X_i)\\\\\n",
    "\\text{reg_preds_t} \\rightarrow~& \\hat{g}_0(X_i) (1 - D_i) + \\hat{g}_1(X_i) D_i &\n",
    "\\text{reg_one_preds_t} \\rightarrow~& \\hat{g}_1(X_i) &\n",
    "\\text{reg_zero_preds_t} \\rightarrow~& \\hat{g}_0(X_i)\\\\\n",
    "\\text{res_preds} \\rightarrow~& \\hat{q}(X_i) &\n",
    "\\text{prop_preds} \\rightarrow~& \\hat{p}(X_i)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfit:\n",
    "    if groups is None:\n",
    "        cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "        splits = list(cv.split(X, D))\n",
    "    else:\n",
    "        cv = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "        splits = list(cv.split(X, D, groups=groups))\n",
    "else:\n",
    "    splits = [(np.arange(X.shape[0]), np.arange(X.shape[0]))]\n",
    "\n",
    "n = X.shape[0]\n",
    "reg_preds_t = np.zeros(n)\n",
    "reg_zero_preds_t = np.zeros(n)\n",
    "reg_one_preds_t = np.zeros(n)\n",
    "\n",
    "DX = np.column_stack((D, X))\n",
    "for train, test in splits:\n",
    "    reg_zero = model_reg_zero().fit(X.iloc[train][D[train]==0], y[train][D[train]==0])\n",
    "    reg_one = model_reg_one().fit(X.iloc[train][D[train]==1], y[train][D[train]==1])\n",
    "    reg_zero_preds_t[test] = reg_zero.predict(X.iloc[test])\n",
    "    reg_one_preds_t[test] = reg_one.predict(X.iloc[test])\n",
    "    reg_preds_t[test] = reg_zero_preds_t[test] * (1 - D[test]) + reg_one_preds_t[test] * D[test]\n",
    "\n",
    "res_preds = cross_val_predict(model_y(), X, y, cv=splits)\n",
    "prop_preds = cross_val_predict(model_t(), X, D, cv=splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATE Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the doubly robust method. In particular, we construct the doubly robust variables\n",
    "\\begin{align}\n",
    "Y_i^{DR}(\\hat{g},\\hat{p}) := \\hat{g}_1(X_i) - \\hat{g}_0(X_i) + (Y_i - \\hat{g}_{D_i}(X_i))\\frac{D_i - \\hat{p}(X_i)}{\\hat{p}(X_i) (1-\\hat{p}(X_i))}\n",
    "\\end{align}\n",
    "and then we estimate:\n",
    "\\begin{align}\n",
    "ATE = E_n\\left[Y^{DR}(\\hat{g},\\hat{p})\\right]\n",
    "\\end{align}\n",
    "This should be more efficient in the worst-case and should be returning a consistent estimate of the ATE even beyond RCTs and will also correctly account for any imbalances or violations of the randomization assumption in an RCT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_preds = reg_one_preds_t - reg_zero_preds_t\n",
    "dr_preds += (y - reg_preds_t) * (D - prop_preds) / np.clip(prop_preds * (1 - prop_preds), cov_clip, np.inf)\n",
    "\n",
    "if groups is None:\n",
    "    display(OLS(dr_preds, np.ones((len(dr_preds), 1))).fit(cov_type='HC1').summary())\n",
    "else:\n",
    "    display(OLS(dr_preds, np.ones((len(dr_preds), 1))).fit(cov_type='cluster', cov_kwds={'groups': groups}).summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Linear CATE Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the doubly robust variables as pseudo-outcomes in an OLS regression, so as to estimate the best linear approximation of the true CATE. In an RCT, these should be similar to the coefficients recovered in a plain interactive OLS regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_preds = reg_one_preds_t - reg_zero_preds_t\n",
    "dr_preds += (y - reg_preds_t) * (D - prop_preds) / np.clip(prop_preds * (1 - prop_preds), cov_clip, np.inf)\n",
    "\n",
    "dfX = X.copy()\n",
    "dfX = dfX - dfX.mean(axis=0)\n",
    "dfX['const'] = 1\n",
    "if groups is None:\n",
    "    lr = OLS(dr_preds, dfX).fit(cov_type='HC1')\n",
    "    cov = lr.get_robustcov_results(cov_type='HC1')\n",
    "else:\n",
    "    lr = OLS(dr_preds, dfX).fit(cov_type='cluster', cov_kwds={'groups': groups})\n",
    "    cov = lr.get_robustcov_results(cov_type='cluster', groups=groups)\n",
    "lr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simultaneous (Joint) Confidence Intervals\n",
    "We can also perform joint inference on all these parameters controlling the joint probability of failure of the confidence intervals by 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = cov.cov_params()\n",
    "S = np.diag(np.diagonal(V)**(-1/2))\n",
    "epsilon = np.random.multivariate_normal(np.zeros(V.shape[0]), S @ V @ S, size=(1000))\n",
    "critical = np.percentile(np.max(np.abs(epsilon), axis=1), 95)\n",
    "stderr = np.diagonal(V)**(1/2)\n",
    "lb = cov.params - critical * stderr\n",
    "ub = cov.params + critical * stderr\n",
    "jointsummary = pd.DataFrame({'coef': cov.params,\n",
    "                             'std err': stderr,\n",
    "                             'lb': lb,\n",
    "                             'ub': ub,\n",
    "                             'statsig': ['' if ((l <= 0) & (0 <= u)) else '**' for (l, u) in zip(lb, ub)]},\n",
    "                            index=dfX.columns)\n",
    "display(jointsummary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence Intervals on BLP of CATE Predictions\n",
    "\n",
    "We can also produce confidence intervals for the predictions of the CATE at particular points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.unique(np.percentile(dfX[xfeat], np.arange(0, 110, 20)))\n",
    "\n",
    "Zpd = pd.DataFrame(np.tile(np.median(dfX, axis=0, keepdims=True), (len(grid), 1)),\n",
    "                    columns=dfX.columns)\n",
    "Zpd[xfeat] = grid\n",
    "\n",
    "pred_df = lr.get_prediction(Zpd).summary_frame()\n",
    "preds, lb, ub = pred_df['mean'].values, pred_df['mean_ci_lower'].values, pred_df['mean_ci_upper'].values\n",
    "preds = preds.flatten()\n",
    "lb = lb.flatten()\n",
    "ub = ub.flatten()\n",
    "plt.errorbar(Zpd[xfeat], preds, yerr=(preds-lb, ub-preds))\n",
    "plt.xlabel(xfeat)\n",
    "plt.ylabel('Predicted CATE (at median value of other features)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simultaneous (Joint) Confidence Intervals on BLP of CATE Predictions\n",
    "\n",
    "And even simultaneous inference on all these predictions that controls the joint failure probability of these confidence intervals to be at most 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsV = Zpd.values @ V @ Zpd.values.T\n",
    "predsS = np.diag(np.diagonal(predsV)**(-1/2))\n",
    "epsilon = np.random.multivariate_normal(np.zeros(predsV.shape[0]), predsS @ predsV @ predsS, size=(1000))\n",
    "critical = np.percentile(np.max(np.abs(epsilon), axis=1), 95)\n",
    "stderr = np.diagonal(predsV)**(1/2)\n",
    "lb = preds - critical * stderr\n",
    "ub = preds + critical * stderr\n",
    "\n",
    "plt.errorbar(Zpd[xfeat], preds, yerr=(preds-lb, ub-preds))\n",
    "plt.xlabel(xfeat)\n",
    "plt.ylabel('Predicted CATE (at median value of other features)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpler Best Linear Projections of CATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "df = X.copy()\n",
    "df['dr'] = dr_preds\n",
    "if groups is None:\n",
    "    lr = ols('dr ~ ' + blp_formula, df).fit(cov_type='HC1')\n",
    "else:\n",
    "    lr = ols('dr ~ ' + blp_formula, df).fit(cov_type='cluster', cov_kwds={'groups': groups})\n",
    "lr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.unique(np.percentile(X[xfeat], np.arange(0, 102, 2)))\n",
    "Xpd = pd.DataFrame(np.tile(np.median(X, axis=0, keepdims=True), (len(grid), 1)),\n",
    "                    columns=X.columns)\n",
    "Xpd[xfeat] = grid\n",
    "pred_df = lr.get_prediction(Xpd).summary_frame(alpha=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Xpd[xfeat], pred_df['mean'])\n",
    "plt.fill_between(Xpd[xfeat], pred_df['mean_ci_lower'], pred_df['mean_ci_upper'], alpha=.4)\n",
    "plt.xlabel(xfeat + ' (other features fixed at median value)')\n",
    "plt.title('Predicted CATE BLP: cate ~' + blp_formula)\n",
    "plt.ylabel('CATE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "df = X.copy()\n",
    "df['dr'] = dr_preds\n",
    "if groups is None:\n",
    "    lr = ols('dr ~ ' + blp_formula2, df).fit(cov_type='HC1')\n",
    "else:\n",
    "    lr = ols('dr ~ ' + blp_formula2, df).fit(cov_type='cluster', cov_kwds={'groups': groups})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.unique(np.percentile(X[xfeat], np.arange(0, 102, 2)))\n",
    "Xpd = pd.DataFrame(np.tile(np.median(X, axis=0, keepdims=True), (len(grid), 1)),\n",
    "                    columns=X.columns)\n",
    "Xpd[xfeat] = grid\n",
    "pred_df2 = lr.get_prediction(Xpd).summary_frame(alpha=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Xpd[xfeat], pred_df2['mean'])\n",
    "plt.fill_between(Xpd[xfeat], pred_df2['mean_ci_lower'], pred_df2['mean_ci_upper'], alpha=.4)\n",
    "plt.xlabel(xfeat + ' (other features fixed at median value)')\n",
    "plt.ylabel('CATE')\n",
    "plt.title('cate ~' + blp_formula2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Parametric Confidence Intervals on CATE Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now move on to the subject of constructing confidence intervals for the predictions of CATE models. Confidence intervals for CATE predictions is an inherently harder task. In its generality it is at least as hard as constructing confidence intervals for the predictions of a non-parametric regression function; which is a statistically daunting task. \n",
    "\n",
    "We will use data-adaptive approaches like random forests to side step the curse of dimensionality and potentially adapt to sparsity in the regression function (though theoretically such an adaptivity is in the worst case imposssible; it tends to work well in practice). This is the approach taken by CausalForests or Doubly Robust Forests that are both based on the idea of Generalized Random Forests, which is an extension of classical forests for solving problems defined via conditional moment restrictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Parametric Confidence Intervals with Causal Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(standard errors here ignore cluster/group correlations if groups are not `None`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hetero_feats == 'all':\n",
    "    hetero_feats = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = X[hetero_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Z.shape[0] > 1e6:\n",
    "    min_samples_leaf = 500\n",
    "    max_samples = 0.05\n",
    "else:\n",
    "    min_samples_leaf = 50\n",
    "    max_samples = .4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.grf import CausalForest\n",
    "\n",
    "yres = y - res_preds\n",
    "Dres = D - prop_preds\n",
    "cf = CausalForest(4000, criterion='het', max_depth=None,\n",
    "                  max_samples=max_samples,\n",
    "                  min_samples_leaf=min_samples_leaf,\n",
    "                  min_weight_fraction_leaf=.0,\n",
    "                  random_state=random_seed)\n",
    "cf.fit(Z, Dres, yres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feat = np.argsort(cf.feature_importances_)[-1]\n",
    "print(Z.columns[top_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.unique(np.percentile(Z.iloc[:, top_feat], np.arange(0, 105, 5)))\n",
    "Zpd = pd.DataFrame(np.tile(np.median(Z, axis=0, keepdims=True), (len(grid), 1)),\n",
    "                    columns=Z.columns)\n",
    "Zpd.iloc[:, top_feat] = grid\n",
    "\n",
    "preds, lb, ub = cf.predict(Zpd, interval=True, alpha=.1)\n",
    "preds = preds.flatten()\n",
    "lb = lb.flatten()\n",
    "ub = ub.flatten()\n",
    "plt.errorbar(Zpd.iloc[:, top_feat], preds, yerr=(preds-lb, ub-preds))\n",
    "plt.xlabel(Zpd.columns[top_feat])\n",
    "plt.ylabel('Predicted CATE (at median value of other features)')\n",
    "plt.savefig(f'{data}-causal-forest.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if semi_synth:\n",
    "    true_proj = true_cate(X)\n",
    "    preds, lb, ub = cf.predict(Z, interval=True, alpha=.1)\n",
    "    preds = preds.flatten()\n",
    "    lb = lb.flatten()\n",
    "    ub = ub.flatten()\n",
    "    inds = np.argsort(true_proj)\n",
    "    plt.plot(true_proj[inds], preds[inds])\n",
    "    plt.fill_between(true_proj[inds], lb[inds].flatten(), ub[inds].flatten(), alpha=.4)\n",
    "    plt.plot(np.linspace(np.min(true_proj), np.max(true_proj), 100),\n",
    "             np.linspace(np.min(true_proj), np.max(true_proj), 100))\n",
    "    plt.xlabel('True CATE')\n",
    "    plt.ylabel('Predicted CATE')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_feats = Z.columns[np.argsort(cf.feature_importances_)[::-1]]\n",
    "important_feats[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "for it, feature in enumerate(important_feats[:4]):\n",
    "    plt.subplot(2, 2, it + 1)\n",
    "    grid = np.unique(np.percentile(Z[feature], np.arange(0, 105, 5)))\n",
    "    Zpd = pd.DataFrame(np.tile(np.median(Z, axis=0, keepdims=True), (len(grid), 1)),\n",
    "                        columns=Z.columns)\n",
    "    Zpd[feature] = grid\n",
    "\n",
    "    preds, lb, ub = cf.predict(Zpd, interval=True, alpha=.1)\n",
    "    preds = preds.flatten()\n",
    "    lb = lb.flatten()\n",
    "    ub = ub.flatten()\n",
    "    plt.errorbar(Zpd[feature], preds, yerr=(preds-lb, ub-preds))\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Predicted CATE')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{data}-cf-marginal-plots.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Parametric Confidence Intervals with Doubly Robust Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(standard errors here ignore cluster/group correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.grf import RegressionForest\n",
    "\n",
    "drrf = RegressionForest(4000, max_depth=5,\n",
    "                        max_samples=max_samples,\n",
    "                        min_samples_leaf=min_samples_leaf,\n",
    "                        min_weight_fraction_leaf=.0,\n",
    "                        random_state=random_seed)\n",
    "drrf.fit(Z, dr_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feat = np.argsort(drrf.feature_importances_)[-1]\n",
    "print(Z.columns[top_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.unique(np.percentile(Z.iloc[:, top_feat], np.arange(0, 105, 5)))\n",
    "Zpd = pd.DataFrame(np.tile(np.median(Z.values, axis=0, keepdims=True), (len(grid), 1)),\n",
    "                    columns=Z.columns)\n",
    "Zpd.iloc[:, top_feat] = grid\n",
    "\n",
    "preds, lb, ub = drrf.predict(Zpd, interval=True, alpha=.1)\n",
    "preds = preds.flatten()\n",
    "lb = lb.flatten()\n",
    "ub = ub.flatten()\n",
    "plt.errorbar(Zpd.iloc[:, top_feat], preds, yerr=(preds-lb, ub-preds))\n",
    "plt.xlabel(Zpd.columns[top_feat])\n",
    "plt.ylabel('Predicted CATE (at median value of other features)')\n",
    "plt.savefig(f'{data}-doubly-robust-forest.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_feats = Z.columns[np.argsort(drrf.feature_importances_)[::-1]]\n",
    "important_feats[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "for it, feature in enumerate(important_feats[:4]):\n",
    "    plt.subplot(2, 2, it + 1)\n",
    "    grid = np.unique(np.percentile(Z[feature], np.arange(0, 105, 5)))\n",
    "    Zpd = pd.DataFrame(np.tile(np.median(Z, axis=0, keepdims=True), (len(grid), 1)),\n",
    "                        columns=Z.columns)\n",
    "    Zpd[feature] = grid\n",
    "\n",
    "    preds, lb, ub = drrf.predict(Zpd, interval=True, alpha=.1)\n",
    "    preds = preds.flatten()\n",
    "    lb = lb.flatten()\n",
    "    ub = ub.flatten()\n",
    "    plt.errorbar(Zpd[feature], preds, yerr=(preds-lb, ub-preds))\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Predicted CATE')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{data}-drrf-marginal-plots.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if semi_synth:\n",
    "    true_proj = true_cate(X)\n",
    "    preds, lb, ub = drrf.predict(Z, interval=True, alpha=.1)\n",
    "    preds = preds.flatten()\n",
    "    lb = lb.flatten()\n",
    "    ub = ub.flatten()\n",
    "    inds = np.argsort(true_proj)\n",
    "    plt.plot(true_proj[inds], preds[inds])\n",
    "    plt.fill_between(true_proj[inds], lb[inds].flatten(), ub[inds].flatten(), alpha=.4)\n",
    "    plt.plot(np.linspace(np.min(true_proj), np.max(true_proj), 100),\n",
    "             np.linspace(np.min(true_proj), np.max(true_proj), 100))\n",
    "    plt.xlabel('True CATE')\n",
    "    plt.ylabel('Predicted CATE')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose our goal is to estimate the best treatment policy $\\pi: Z \\to \\{0, 1\\}$. The policy gains over no treatment for any policy $\\pi$ can be identified as:\n",
    "\\begin{align}\n",
    "V(\\pi) := E[\\pi(Z)\\, (Y(1) - Y(0))] = E\\left[\\pi(Z)\\, Y^{DR}(g,p)\\right]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the learned policy out of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = (dr_preds - treatment_cost) * policy(Z)\n",
    "point = np.mean(pi)\n",
    "stderr = np.sqrt(np.var(pi) / pi.shape[0])\n",
    "print(f\"{point:.5f}, {stderr:.5f}, {point - 1.96 * stderr:.5f}, {point + 1.96 * stderr:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As compared to treating everyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = (dr_preds - treatment_cost)\n",
    "point = np.mean(pi)\n",
    "stderr = np.sqrt(np.var(pi) / pi.shape[0])\n",
    "print(f\"{point:.5f}, {stderr:.5f}, {point - 1.96 * stderr:.5f}, {point + 1.96 * stderr:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
