{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the `econml` and `wget` python packages are not installed on your machine install them by running the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: econml in c:\\programdata\\anaconda3\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from econml) (1.24.3)\n",
      "Requirement already satisfied: scipy>1.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from econml) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn<1.3,>0.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from econml) (1.2.2)\n",
      "Requirement already satisfied: sparse in c:\\programdata\\anaconda3\\lib\\site-packages (from econml) (0.15.1)\n",
      "Requirement already satisfied: joblib>=0.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from econml) (1.2.0)\n",
      "Requirement already satisfied: statsmodels>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from econml) (0.14.0)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from econml) (2.0.3)\n",
      "Requirement already satisfied: shap<0.42.0,>=0.38.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from econml) (0.41.0)\n",
      "Requirement already satisfied: lightgbm in c:\\programdata\\anaconda3\\lib\\site-packages (from econml) (4.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn<1.3,>0.22.0->econml) (2.2.0)\n",
      "Requirement already satisfied: tqdm>4.25.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from shap<0.42.0,>=0.38.1->econml) (4.65.0)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from shap<0.42.0,>=0.38.1->econml) (23.1)\n",
      "Requirement already satisfied: slicer==0.0.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from shap<0.42.0,>=0.38.1->econml) (0.0.7)\n",
      "Requirement already satisfied: numba in c:\\programdata\\anaconda3\\lib\\site-packages (from shap<0.42.0,>=0.38.1->econml) (0.57.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\programdata\\anaconda3\\lib\\site-packages (from shap<0.42.0,>=0.38.1->econml) (2.2.1)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from statsmodels>=0.10->econml) (0.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->econml) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->econml) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->econml) (2023.3)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\programdata\\anaconda3\\lib\\site-packages (from numba->shap<0.42.0,>=0.38.1->econml) (0.40.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from patsy>=0.5.2->statsmodels>=0.10->econml) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>4.25.0->shap<0.42.0,>=0.38.1->econml) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install econml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wget in c:\\programdata\\anaconda3\\lib\\site-packages (3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the necessary components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.special\n",
    "from sklearn.linear_model import LassoCV, LinearRegression, ElasticNetCV\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.base import clone\n",
    "import joblib\n",
    "from statsmodels.api import OLS\n",
    "from sklearn.model_selection import StratifiedGroupKFold, GroupKFold, KFold, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [................................................................................] 5006 / 5006"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'myxgb.py'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wget\n",
    "import os\n",
    "\n",
    "if os.path.exists('datasets.py'):\n",
    "    os.remove('datasets.py')\n",
    "wget.download('https://raw.githubusercontent.com/CausalAIBook/MetricsMLNotebooks/main/T/datasets.py')\n",
    "\n",
    "if os.path.exists('myxgb.py'):\n",
    "    os.remove('myxgb.py')\n",
    "wget.download('https://raw.githubusercontent.com/CausalAIBook/MetricsMLNotebooks/main/T/myxgb.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the High Level Parameters for the Notebook\n",
    "\n",
    "The 401k dataset is downloaded from the source by the code and no need to further download anything:\n",
    "https://raw.githubusercontent.com/CausalAIBook/MetricsMLNotebooks/main/data/401k.csv\n",
    "\n",
    "The welfare dataset is downloaded from the source by the code and no need to further download anything:\n",
    "https://github.com/gsbDBI/ExperimentData/blob/master/Welfare/ProcessedData/welfarenolabel3.csv \n",
    "\n",
    "It is drawn from the analysis in this paper: [Green and Kern, 2012, Modeling Heterogeneous Treatment Effects in Survey Experiments with Bayesian Additive Regression Trees](https://github.com/gsbDBI/ExperimentData/blob/master/Welfare/Green%20and%20Kern%20BART.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = '401k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == '401k':\n",
    "    verbose = 0 # verbosity of auto-ml\n",
    "    n_splits = 5 # cross-fitting and cross-validation splits\n",
    "    cfit = False\n",
    "    data = '401k' # which dataset, one of {'401k', 'criteo', 'welfare', 'poverty', 'star'}\n",
    "    plot = True # whether to plot results\n",
    "    xfeat = 'inc' # feature to use as x axis in plotting, e.g. for criteo 'f1', for 401k 'inc', for welfare 'polviews'\n",
    "    # Formula for the BLP of CATE regression.\n",
    "    blp_formula = 'np.log(inc)' # e.g. 'f1' for criteo, np.log(inc)' for 401k, 'C(polviews)' for the welfare case.\n",
    "    blp_formula_short = 'log(inc)'\n",
    "    blp_formula2 = 'np.log(inc) + np.power(np.log(inc), 2) + np.power(np.log(inc), 3) + np.power(np.log(inc), 4)'\n",
    "    blp_formula2_short = 'poly(log(inc), 4)'\n",
    "    hetero_feats = 'all' # list of subset of features to be used for CATE model or the string 'all' for everything\n",
    "    cov_clip = .01 # clipping of treatment variance p(x)*(1-p(x)), whenever used in inverse propensities\n",
    "    binary_y = False\n",
    "    random_seed = 1\n",
    "    # treatment policy to evaluate\n",
    "    policy = lambda x: x['inc'] > 30000\n",
    "    # cost of treatment when performing optimal policy learning, can also be viewed as \"threshold for treatment\"\n",
    "    treatment_cost = 4000\n",
    "\n",
    "    ## For semi-synthetic data generation\n",
    "    semi_synth = False # Whether true outcome y should be replaced by a fake outcome from a known CEF\n",
    "    simple_synth = True # Whether the true CEF of the fake y should be simple or fitted from data\n",
    "    max_depth = 2 # max depth of random forest during for semi-synthetic model fitting\n",
    "    scale = .2 # magnitude of noise in semi-synthetic data\n",
    "    def simple_true_cef(D, X): # simple CEF of the outcome for semi-synthetic data\n",
    "        return .5 * np.array(X)[:, 1] * D + np.array(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'welfare':\n",
    "    verbose = 0 # verbosity of auto-ml\n",
    "    n_splits = 5 # cross-fitting and cross-validation splits\n",
    "    cfit = True\n",
    "    data = 'welfare' # which dataset, one of {'401k', 'criteo', 'welfare', 'poverty', 'star'}\n",
    "    plot = True # whether to plot results\n",
    "    xfeat = 'polviews' # feature to use as x axis in plotting, e.g. for criteo 'f1', for 401k 'inc', for welfare 'polviews'\n",
    "    # Formula for the BLP of CATE regression.\n",
    "    blp_formula = 'C(polviews)' # e.g. 'f1' for criteo, np.log(inc)' for 401k, 'C(polviews)' for the welfare case.\n",
    "    blp_formula_short = 'C(polviews)'\n",
    "    blp_formula2 = 'polviews'\n",
    "    blp_formula2_short = 'polviews'\n",
    "    hetero_feats = 'all' # list of subset of features to be used for CATE model or the string 'all' for everything\n",
    "    cov_clip = .01 # clipping of treatment variance p(x)*(1-p(x)), whenever used in inverse propensities\n",
    "    binary_y = True\n",
    "    random_seed = 1\n",
    "    # treatment policy to evaluate\n",
    "    policy = lambda x: x['polviews'] > 3\n",
    "    # cost of treatment when performing optimal policy learning, can also be viewed as \"threshold for treatment\"\n",
    "    treatment_cost = -.3\n",
    "\n",
    "    ## For semi-synthetic data generation\n",
    "    semi_synth = False # Whether true outcome y should be replaced by a fake outcome from a known CEF\n",
    "    simple_synth = True # Whether the true CEF of the fake y should be simple or fitted from data\n",
    "    max_depth = 2 # max depth of random forest during for semi-synthetic model fitting\n",
    "    scale = .2 # magnitude of noise in semi-synthetic data\n",
    "    def simple_true_cef(D, X): # simple CEF of the outcome for semi-synthetic data\n",
    "        return .5 * np.array(X)[:, 1] * D + np.array(X)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching and Constructing the Dataset\n",
    "\n",
    "The data generator also allows for semi-synthetic data generation where the ground truth CATE is known, which can be used for evaluation of different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import fetch_data_generator\n",
    "\n",
    "get_data, abtest, true_cef, true_cate = fetch_data_generator(data=data, semi_synth=semi_synth,\n",
    "                                                             simple_synth=simple_synth,\n",
    "                                                             scale=scale, true_f=simple_true_cef,\n",
    "                                                             max_depth=max_depth)\n",
    "X, D, y, groups = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "if semi_synth:\n",
    "    true_ate = np.mean(true_cate(X))\n",
    "    print(f'True ATE: {true_ate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(cate, preds):\n",
    "    return np.sqrt(np.mean((cate - preds)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "We now have our data $X$, $D$, $y$, of controls, treatments and outcomes. In some datasets, we also have \"groups\", also known as \"clusters\". These are group ids, that define a group of samples that are believed to be correlated through unobesrved factors. For instance, in randomized experiments when a whole class is being treated and we have data at the student level, the students in a class constitute a cluster, as their outcome variables are most probably correlated. In such settings, it is helpful to account for the cluster correlations when calculating confidence intervals and when performing sample splitting for either cross-validation or for nuisance estimation.\n",
    "\n",
    "We will be assuming throughout that conditional ignorability is satisfied if we control for all the variables $X$, i.e. the potential outcomes $Y(1), Y(0)$ satisfy\n",
    "\\begin{align}\n",
    "Y(1), Y(0) ~\\perp\\hspace{-1em}\\perp~D \\mid X\n",
    "\\end{align}\n",
    "Equivalently, we assume that the DAG the corresponds to our setting satisfies that $X$ is a valid adjustment set between $D$ and $Y$, i.e. it blocks all backdoor paths in the DAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>inc</th>\n",
       "      <th>fsize</th>\n",
       "      <th>educ</th>\n",
       "      <th>db</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>twoearn</th>\n",
       "      <th>pira</th>\n",
       "      <th>nohs</th>\n",
       "      <th>hs</th>\n",
       "      <th>smcol</th>\n",
       "      <th>col</th>\n",
       "      <th>hown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9716.000000</td>\n",
       "      <td>9716.000000</td>\n",
       "      <td>9716.000000</td>\n",
       "      <td>9716.000000</td>\n",
       "      <td>9716.000000</td>\n",
       "      <td>9716.000000</td>\n",
       "      <td>9716.000000</td>\n",
       "      <td>9716.000000</td>\n",
       "      <td>9716.000000</td>\n",
       "      <td>9716.000000</td>\n",
       "      <td>9716.000000</td>\n",
       "      <td>9716.000000</td>\n",
       "      <td>9716.000000</td>\n",
       "      <td>9716.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.034891</td>\n",
       "      <td>36462.224269</td>\n",
       "      <td>2.868361</td>\n",
       "      <td>13.192672</td>\n",
       "      <td>0.271202</td>\n",
       "      <td>0.603746</td>\n",
       "      <td>0.205949</td>\n",
       "      <td>0.380198</td>\n",
       "      <td>0.238678</td>\n",
       "      <td>0.127419</td>\n",
       "      <td>0.379477</td>\n",
       "      <td>0.247118</td>\n",
       "      <td>0.245986</td>\n",
       "      <td>0.635241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.337014</td>\n",
       "      <td>22193.821846</td>\n",
       "      <td>1.541154</td>\n",
       "      <td>2.787505</td>\n",
       "      <td>0.444603</td>\n",
       "      <td>0.489143</td>\n",
       "      <td>0.404414</td>\n",
       "      <td>0.485460</td>\n",
       "      <td>0.426298</td>\n",
       "      <td>0.333459</td>\n",
       "      <td>0.485282</td>\n",
       "      <td>0.431358</td>\n",
       "      <td>0.430692</td>\n",
       "      <td>0.481387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>4080.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>19648.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>31473.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>48071.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>118599.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age            inc        fsize         educ           db  \\\n",
       "count  9716.000000    9716.000000  9716.000000  9716.000000  9716.000000   \n",
       "mean     41.034891   36462.224269     2.868361    13.192672     0.271202   \n",
       "std      10.337014   22193.821846     1.541154     2.787505     0.444603   \n",
       "min      25.000000    4080.000000     1.000000     1.000000     0.000000   \n",
       "25%      32.000000   19648.500000     2.000000    12.000000     0.000000   \n",
       "50%      40.000000   31473.000000     3.000000    12.000000     0.000000   \n",
       "75%      48.000000   48071.250000     4.000000    15.000000     1.000000   \n",
       "max      64.000000  118599.000000    13.000000    18.000000     1.000000   \n",
       "\n",
       "              marr         male      twoearn         pira         nohs  \\\n",
       "count  9716.000000  9716.000000  9716.000000  9716.000000  9716.000000   \n",
       "mean      0.603746     0.205949     0.380198     0.238678     0.127419   \n",
       "std       0.489143     0.404414     0.485460     0.426298     0.333459   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                hs        smcol          col         hown  \n",
       "count  9716.000000  9716.000000  9716.000000  9716.000000  \n",
       "mean      0.379477     0.247118     0.245986     0.635241  \n",
       "std       0.485282     0.431358     0.430692     0.481387  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     1.000000  \n",
       "75%       1.000000     0.000000     0.000000     1.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(D)\n",
    "plt.title('Treatment')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(y)\n",
    "plt.title('Outcome')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.025</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.025</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   211.2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 14 Feb 2024</td> <th>  Prob (F-statistic):</th>  <td>2.35e-47</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:05:56</td>     <th>  Log-Likelihood:    </th> <td>-1.1960e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  9716</td>      <th>  AIC:               </th>  <td>2.392e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  9714</td>      <th>  BIC:               </th>  <td>2.392e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC1</td>       <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 9925.5573</td> <td>  596.973</td> <td>   16.626</td> <td> 0.000</td> <td> 8755.511</td> <td> 1.11e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> 1.769e+04</td> <td> 1217.458</td> <td>   14.533</td> <td> 0.000</td> <td> 1.53e+04</td> <td> 2.01e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>15808.021</td> <th>  Durbin-Watson:     </th>   <td>   2.001</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>17742973.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>10.566</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>211.282</td>  <th>  Cond. No.          </th>   <td>    2.43</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC1)"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &      0.025    \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &      0.025    \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &      211.2    \\\\\n",
       "\\textbf{Date:}             & Wed, 14 Feb 2024 & \\textbf{  Prob (F-statistic):} &   2.35e-47    \\\\\n",
       "\\textbf{Time:}             &     13:05:56     & \\textbf{  Log-Likelihood:    } & -1.1960e+05   \\\\\n",
       "\\textbf{No. Observations:} &        9716      & \\textbf{  AIC:               } &  2.392e+05    \\\\\n",
       "\\textbf{Df Residuals:}     &        9714      & \\textbf{  BIC:               } &  2.392e+05    \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &               \\\\\n",
       "\\textbf{Covariance Type:}  &       HC1        & \\textbf{                     } &               \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    9925.5573  &      596.973     &    16.626  &         0.000        &     8755.511    &     1.11e+04     \\\\\n",
       "\\textbf{x1}    &    1.769e+04  &     1217.458     &    14.533  &         0.000        &     1.53e+04    &     2.01e+04     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 15808.021 & \\textbf{  Durbin-Watson:     } &      2.001    \\\\\n",
       "\\textbf{Prob(Omnibus):} &    0.000  & \\textbf{  Jarque-Bera (JB):  } & 17742973.002  \\\\\n",
       "\\textbf{Skew:}          &   10.566  & \\textbf{  Prob(JB):          } &       0.00    \\\\\n",
       "\\textbf{Kurtosis:}      &  211.282  & \\textbf{  Cond. No.          } &       2.43    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors are heteroscedasticity robust (HC1)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.025\n",
       "Model:                            OLS   Adj. R-squared:                  0.025\n",
       "Method:                 Least Squares   F-statistic:                     211.2\n",
       "Date:                Wed, 14 Feb 2024   Prob (F-statistic):           2.35e-47\n",
       "Time:                        13:05:56   Log-Likelihood:            -1.1960e+05\n",
       "No. Observations:                9716   AIC:                         2.392e+05\n",
       "Df Residuals:                    9714   BIC:                         2.392e+05\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:                  HC1                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       9925.5573    596.973     16.626      0.000    8755.511    1.11e+04\n",
       "x1          1.769e+04   1217.458     14.533      0.000    1.53e+04    2.01e+04\n",
       "==============================================================================\n",
       "Omnibus:                    15808.021   Durbin-Watson:                   2.001\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         17742973.002\n",
       "Skew:                          10.566   Prob(JB):                         0.00\n",
       "Kurtosis:                     211.282   Cond. No.                         2.43\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC1)\n",
       "\"\"\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple two means estimate which would be wrong unless an randomized trial\n",
    "OLS(y, np.hstack([np.ones((D.shape[0], 1)), D.reshape(-1, 1)])).fit(cov_type='HC1').summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuisance Cross-Fitted Estimation and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will estimate regression models for each of the nuisance functions that arise in CATE learning approaches. The five models correspond to the following five predictive problems:\n",
    "\\begin{align}\n",
    "\\text{model_y} ~\\rightarrow~& q(x) := E[Y\\mid X=x]\\\\\n",
    "\\text{model_t} ~\\rightarrow~& p(x) := E[D\\mid X=x] = \\Pr(D=1\\mid X=x)\\\\\n",
    "\\text{model_reg_zero} ~\\rightarrow~& g_0(x) := E[Y\\mid D=0, X=x]\\\\\n",
    "\\text{model_reg_one} ~\\rightarrow~& g_1(x) := E[Y\\mid D=1, X=x]\\\\\n",
    "\\end{align}\n",
    "We will use gradient boosting regression with early stopping for each of these models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the nuisance models we perform cross-fitting to get out-of-fold predictions from each of these nuisance models. At the end of this process, we will have for each sample $i$, the following out-of-fold nuisance values:\n",
    "\\begin{align}\n",
    "\\text{reg_preds_t} \\rightarrow~& \\hat{g}_0(X_i) (1 - D_i) + \\hat{g}_1(X_i) D_i &\n",
    "\\text{reg_one_preds_t} \\rightarrow~& \\hat{g}_1(X_i) &\n",
    "\\text{reg_zero_preds_t} \\rightarrow~& \\hat{g}_0(X_i)\\\\\n",
    "\\text{res_preds} \\rightarrow~& \\hat{q}(X_i) &\n",
    "\\text{prop_preds} \\rightarrow~& \\hat{p}(X_i)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myxgb import xgb_reg, xgb_clf\n",
    "\n",
    "auto_reg = lambda: xgb_reg(random_seed)\n",
    "auto_clf = lambda: xgb_clf(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfit:\n",
    "    if groups is None:\n",
    "        cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "        splits = list(cv.split(X, D))\n",
    "    else:\n",
    "        cv = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "        splits = list(cv.split(X, D, groups=groups))\n",
    "else:\n",
    "    splits = [(np.arange(X.shape[0]), np.arange(X.shape[0]))]\n",
    "\n",
    "n = X.shape[0]\n",
    "reg_preds_t = np.zeros(n)\n",
    "reg_zero_preds_t = np.zeros(n)\n",
    "reg_one_preds_t = np.zeros(n)\n",
    "\n",
    "for train, test in splits:\n",
    "    reg_zero = auto_reg().fit(X.iloc[train][D[train]==0], y[train][D[train]==0])\n",
    "    reg_one = auto_reg().fit(X.iloc[train][D[train]==1], y[train][D[train]==1])\n",
    "    reg_zero_preds_t[test] = reg_zero.predict(X.iloc[test])\n",
    "    reg_one_preds_t[test] = reg_one.predict(X.iloc[test])\n",
    "    reg_preds_t[test] = reg_zero_preds_t[test] * (1 - D[test]) + reg_one_preds_t[test] * D[test]\n",
    "\n",
    "res_preds = cross_val_predict(auto_reg(), X, y, cv=splits)\n",
    "prop_preds = cross_val_predict(auto_clf(), X, D, cv=splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Nuisance Model Performance\n",
    "\n",
    "We now also evaluate the performance of the selected models in terms of R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2score(y, ypred):\n",
    "    return 1 - np.mean((y - ypred)**2) / np.var(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 of model for (y ~ X): 0.2501\n",
      "R^2 of model for (D ~ X): 0.1670\n",
      "R^2 of model for (y ~ X | D==0): 0.1947\n",
      "R^2 of model for (y ~ X | D==1): 0.2483\n",
      "R^2 of model for (y ~ D, X): 0.2421\n"
     ]
    }
   ],
   "source": [
    "print(f\"R^2 of model for (y ~ X): {r2score(y, res_preds):.4f}\")\n",
    "print(f\"R^2 of model for (D ~ X): {r2score(D, prop_preds):.4f}\")\n",
    "print(f\"R^2 of model for (y ~ X | D==0): {r2score(y[D==0], reg_zero_preds_t[D==0]):.4f}\")\n",
    "print(f\"R^2 of model for (y ~ X | D==1): {r2score(y[D==1], reg_one_preds_t[D==1]):.4f}\")\n",
    "print(f\"R^2 of model for (y ~ D, X): {r2score(y, reg_preds_t):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doubly-Robust ATE Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the doubly robust method. In particular, we construct the doubly robust variables\n",
    "\\begin{align}\n",
    "Y_i^{DR}(\\hat{g},\\hat{p}) := \\hat{g}_1(X_i) - \\hat{g}_0(X_i) + (Y_i - \\hat{g}_{D_i}(X_i))\\frac{D_i - \\hat{p}(X_i)}{\\hat{p}(X_i) (1-\\hat{p}(X_i))}\n",
    "\\end{align}\n",
    "and then we estimate:\n",
    "\\begin{align}\n",
    "ATE = E_n\\left[Y^{DR}(\\hat{g},\\hat{p})\\right]\n",
    "\\end{align}\n",
    "This should be more efficient in the worst-case and should be returning a consistent estimate of the ATE even beyond RCTs and will also correctly account for any imbalances or violations of the randomization assumption in an RCT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>  -0.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>  -0.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>     nan</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 14 Feb 2024</td> <th>  Prob (F-statistic):</th>   <td>   nan</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:06:27</td>     <th>  Log-Likelihood:    </th> <td>-1.2531e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  9716</td>      <th>  AIC:               </th>  <td>2.506e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  9715</td>      <th>  BIC:               </th>  <td>2.506e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     0</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC1</td>       <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 7804.8706</td> <td>  979.838</td> <td>    7.965</td> <td> 0.000</td> <td> 5884.424</td> <td> 9725.318</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>7532.548</td> <th>  Durbin-Watson:     </th>   <td>   1.974</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>31520906.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-2.089</td>  <th>  Prob(JB):          </th>   <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>282.005</td> <th>  Cond. No.          </th>   <td>    1.00</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC1)"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     -0.000    \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     -0.000    \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &        nan    \\\\\n",
       "\\textbf{Date:}             & Wed, 14 Feb 2024 & \\textbf{  Prob (F-statistic):} &       nan     \\\\\n",
       "\\textbf{Time:}             &     13:06:27     & \\textbf{  Log-Likelihood:    } & -1.2531e+05   \\\\\n",
       "\\textbf{No. Observations:} &        9716      & \\textbf{  AIC:               } &  2.506e+05    \\\\\n",
       "\\textbf{Df Residuals:}     &        9715      & \\textbf{  BIC:               } &  2.506e+05    \\\\\n",
       "\\textbf{Df Model:}         &           0      & \\textbf{                     } &               \\\\\n",
       "\\textbf{Covariance Type:}  &       HC1        & \\textbf{                     } &               \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    7804.8706  &      979.838     &     7.965  &         0.000        &     5884.424    &     9725.318     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 7532.548 & \\textbf{  Durbin-Watson:     } &      1.974    \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 31520906.701  \\\\\n",
       "\\textbf{Skew:}          &  -2.089  & \\textbf{  Prob(JB):          } &       0.00    \\\\\n",
       "\\textbf{Kurtosis:}      & 282.005  & \\textbf{  Cond. No.          } &       1.00    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors are heteroscedasticity robust (HC1)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                      -0.000\n",
       "Model:                            OLS   Adj. R-squared:                 -0.000\n",
       "Method:                 Least Squares   F-statistic:                       nan\n",
       "Date:                Wed, 14 Feb 2024   Prob (F-statistic):                nan\n",
       "Time:                        13:06:27   Log-Likelihood:            -1.2531e+05\n",
       "No. Observations:                9716   AIC:                         2.506e+05\n",
       "Df Residuals:                    9715   BIC:                         2.506e+05\n",
       "Df Model:                           0                                         \n",
       "Covariance Type:                  HC1                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       7804.8706    979.838      7.965      0.000    5884.424    9725.318\n",
       "==============================================================================\n",
       "Omnibus:                     7532.548   Durbin-Watson:                   1.974\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         31520906.701\n",
       "Skew:                          -2.089   Prob(JB):                         0.00\n",
       "Kurtosis:                     282.005   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC1)\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dr_preds = reg_one_preds_t - reg_zero_preds_t\n",
    "dr_preds += (y - reg_preds_t) * (D - prop_preds) / np.clip(prop_preds * (1 - prop_preds), cov_clip, np.inf)\n",
    "\n",
    "if groups is None:\n",
    "    display(OLS(dr_preds, np.ones((len(dr_preds), 1))).fit(cov_type='HC1').summary())\n",
    "else:\n",
    "    display(OLS(dr_preds, np.ones((len(dr_preds), 1))).fit(cov_type='cluster', cov_kwds={'groups': groups}).summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Linear CATE Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the doubly robust variables as pseudo-outcomes in an OLS regression, so as to estimate the best linear approximation of the true CATE. In an RCT, these should be similar to the coefficients recovered in a plain interactive OLS regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX = X.copy()\n",
    "dfX['const'] = 1\n",
    "if groups is None:\n",
    "    lr = OLS(dr_preds, dfX).fit(cov_type='HC1')\n",
    "    cov = lr.get_robustcov_results(cov_type='HC1')\n",
    "else:\n",
    "    lr = OLS(dr_preds, dfX).fit(cov_type='cluster', cov_kwds={'groups': groups})\n",
    "    cov = lr.get_robustcov_results(cov_type='cluster', groups=groups)\n",
    "lr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simultaneous (Joint) Confidence Intervals\n",
    "We can also perform joint inference on all these parameters controlling the joint probability of failure of the confidence intervals by 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = cov.cov_params()\n",
    "S = np.diag(np.diagonal(V)**(-1/2))\n",
    "epsilon = np.random.multivariate_normal(np.zeros(V.shape[0]), S @ V @ S, size=(1000))\n",
    "critical = np.percentile(np.max(np.abs(epsilon), axis=1), 95)\n",
    "stderr = np.diagonal(V)**(1/2)\n",
    "lb = cov.params - critical * stderr\n",
    "ub = cov.params + critical * stderr\n",
    "jointsummary = pd.DataFrame({'coef': cov.params,\n",
    "                             'std err': stderr,\n",
    "                             'lb': lb,\n",
    "                             'ub': ub,\n",
    "                             'statsig': ['' if ((l <= 0) & (0 <= u)) else '**' for (l, u) in zip(lb, ub)]},\n",
    "                            index=dfX.columns)\n",
    "display(jointsummary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence Intervals on BLP of CATE Predictions\n",
    "\n",
    "We can also produce confidence intervals for the predictions of the CATE at particular points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.unique(np.percentile(dfX[xfeat], np.arange(0, 110, 20)))\n",
    "\n",
    "Zpd = pd.DataFrame(np.tile(np.median(dfX, axis=0, keepdims=True), (len(grid), 1)),\n",
    "                    columns=dfX.columns)\n",
    "Zpd[xfeat] = grid\n",
    "\n",
    "pred_df = lr.get_prediction(Zpd).summary_frame()\n",
    "preds, lb, ub = pred_df['mean'].values, pred_df['mean_ci_lower'].values, pred_df['mean_ci_upper'].values\n",
    "preds = preds.flatten()\n",
    "lb = lb.flatten()\n",
    "ub = ub.flatten()\n",
    "plt.errorbar(Zpd[xfeat], preds, yerr=(preds-lb, ub-preds))\n",
    "plt.xlabel(xfeat)\n",
    "plt.ylabel('Predicted CATE (at median value of other features)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simultaneous (Joint) Confidence Intervals on BLP of CATE Predictions\n",
    "\n",
    "And even simultaneous inference on all these predictions that controls the joint failure probability of these confidence intervals to be at most 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsV = Zpd.values @ V @ Zpd.values.T\n",
    "predsS = np.diag(np.diagonal(predsV)**(-1/2))\n",
    "epsilon = np.random.multivariate_normal(np.zeros(predsV.shape[0]), predsS @ predsV @ predsS, size=(1000))\n",
    "critical = np.percentile(np.max(np.abs(epsilon), axis=1), 95)\n",
    "stderr = np.diagonal(predsV)**(1/2)\n",
    "lb = preds - critical * stderr\n",
    "ub = preds + critical * stderr\n",
    "\n",
    "plt.errorbar(Zpd[xfeat], preds, yerr=(preds-lb, ub-preds))\n",
    "plt.xlabel(xfeat)\n",
    "plt.ylabel('Predicted CATE (at median value of other features)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpler Best Linear Projections of CATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "df = X.copy()\n",
    "df['dr'] = dr_preds\n",
    "if groups is None:\n",
    "    lr = ols('dr ~ ' + blp_formula, df).fit(cov_type='HC1')\n",
    "else:\n",
    "    lr = ols('dr ~ ' + blp_formula, df).fit(cov_type='cluster', cov_kwds={'groups': groups})\n",
    "lr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.unique(np.percentile(X[xfeat], np.arange(0, 102, 2)))\n",
    "Xpd = pd.DataFrame(np.tile(np.median(X, axis=0, keepdims=True), (len(grid), 1)),\n",
    "                    columns=X.columns)\n",
    "Xpd[xfeat] = grid\n",
    "pred_df = lr.get_prediction(Xpd).summary_frame(alpha=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Xpd[xfeat], pred_df['mean'])\n",
    "plt.fill_between(Xpd[xfeat], pred_df['mean_ci_lower'], pred_df['mean_ci_upper'], alpha=.4)\n",
    "plt.xlabel(xfeat + ' (other features fixed at median value)')\n",
    "plt.title('Predicted CATE BLP: cate ~' + blp_formula)\n",
    "plt.ylabel('CATE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "df = X.copy()\n",
    "df['dr'] = dr_preds\n",
    "if groups is None:\n",
    "    lr = ols('dr ~ ' + blp_formula2, df).fit(cov_type='HC1')\n",
    "else:\n",
    "    lr = ols('dr ~ ' + blp_formula2, df).fit(cov_type='cluster', cov_kwds={'groups': groups})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.unique(np.percentile(X[xfeat], np.arange(0, 102, 2)))\n",
    "Xpd = pd.DataFrame(np.tile(np.median(X, axis=0, keepdims=True), (len(grid), 1)),\n",
    "                    columns=X.columns)\n",
    "Xpd[xfeat] = grid\n",
    "pred_df2 = lr.get_prediction(Xpd).summary_frame(alpha=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Xpd[xfeat], pred_df2['mean'])\n",
    "plt.fill_between(Xpd[xfeat], pred_df2['mean_ci_lower'], pred_df2['mean_ci_upper'], alpha=.4)\n",
    "plt.xlabel(xfeat + ' (other features fixed at median value)')\n",
    "plt.ylabel('CATE')\n",
    "plt.title('cate ~' + blp_formula2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Parametric Confidence Intervals on CATE Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now move on to the subject of constructing confidence intervals for the predictions of CATE models. Confidence intervals for CATE predictions is an inherently harder task. In its generality it is at least as hard as constructing confidence intervals for the predictions of a non-parametric regression function; which is a statistically daunting task. \n",
    "\n",
    "We will use data-adaptive approaches like random forests to side step the curse of dimensionality and potentially adapt to sparsity in the regression function (though theoretically such an adaptivity is in the worst case imposssible; it tends to work well in practice). This is the approach taken by CausalForests or Doubly Robust Forests that are both based on the idea of Generalized Random Forests, which is an extension of classical forests for solving problems defined via conditional moment restrictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Parametric Confidence Intervals with Causal Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(standard errors here ignore cluster/group correlations if groups are not `None`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hetero_feats == 'all':\n",
    "    hetero_feats = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = X[hetero_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Z.shape[0] > 1e6:\n",
    "    min_samples_leaf = 500\n",
    "    max_samples = 0.05\n",
    "else:\n",
    "    min_samples_leaf = 50\n",
    "    max_samples = .4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.grf import CausalForest\n",
    "\n",
    "yres = y - res_preds\n",
    "Dres = D - prop_preds\n",
    "cf = CausalForest(4000, criterion='het', max_depth=None,\n",
    "                  max_samples=max_samples,\n",
    "                  min_samples_leaf=min_samples_leaf,\n",
    "                  min_weight_fraction_leaf=.0,\n",
    "                  random_state=random_seed)\n",
    "cf.fit(Z, Dres, yres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feat = np.argsort(cf.feature_importances_)[-1]\n",
    "print(Z.columns[top_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.unique(np.percentile(Z.iloc[:, top_feat], np.arange(0, 105, 5)))\n",
    "Zpd = pd.DataFrame(np.tile(np.median(Z, axis=0, keepdims=True), (len(grid), 1)),\n",
    "                    columns=Z.columns)\n",
    "Zpd.iloc[:, top_feat] = grid\n",
    "\n",
    "preds, lb, ub = cf.predict(Zpd, interval=True, alpha=.1)\n",
    "preds = preds.flatten()\n",
    "lb = lb.flatten()\n",
    "ub = ub.flatten()\n",
    "plt.errorbar(Zpd.iloc[:, top_feat], preds, yerr=(preds-lb, ub-preds))\n",
    "plt.xlabel(Zpd.columns[top_feat])\n",
    "plt.ylabel('Predicted CATE (at median value of other features)')\n",
    "plt.savefig(f'{data}-causal-forest.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if semi_synth:\n",
    "    true_proj = true_cate(X)\n",
    "    preds, lb, ub = cf.predict(Z, interval=True, alpha=.1)\n",
    "    preds = preds.flatten()\n",
    "    lb = lb.flatten()\n",
    "    ub = ub.flatten()\n",
    "    inds = np.argsort(true_proj)\n",
    "    plt.plot(true_proj[inds], preds[inds])\n",
    "    plt.fill_between(true_proj[inds], lb[inds].flatten(), ub[inds].flatten(), alpha=.4)\n",
    "    plt.plot(np.linspace(np.min(true_proj), np.max(true_proj), 100),\n",
    "             np.linspace(np.min(true_proj), np.max(true_proj), 100))\n",
    "    plt.xlabel('True CATE')\n",
    "    plt.ylabel('Predicted CATE')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_feats = Z.columns[np.argsort(cf.feature_importances_)[::-1]]\n",
    "important_feats[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "for it, feature in enumerate(important_feats[:4]):\n",
    "    plt.subplot(2, 2, it + 1)\n",
    "    grid = np.unique(np.percentile(Z[feature], np.arange(0, 105, 5)))\n",
    "    Zpd = pd.DataFrame(np.tile(np.median(Z, axis=0, keepdims=True), (len(grid), 1)),\n",
    "                        columns=Z.columns)\n",
    "    Zpd[feature] = grid\n",
    "\n",
    "    preds, lb, ub = cf.predict(Zpd, interval=True, alpha=.1)\n",
    "    preds = preds.flatten()\n",
    "    lb = lb.flatten()\n",
    "    ub = ub.flatten()\n",
    "    plt.errorbar(Zpd[feature], preds, yerr=(preds-lb, ub-preds))\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Predicted CATE')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{data}-cf-marginal-plots.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Parametric Confidence Intervals with Doubly Robust Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(standard errors here ignore cluster/group correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.grf import RegressionForest\n",
    "\n",
    "drrf = RegressionForest(4000, max_depth=5,\n",
    "                        max_samples=max_samples,\n",
    "                        min_samples_leaf=min_samples_leaf,\n",
    "                        min_weight_fraction_leaf=.0,\n",
    "                        random_state=random_seed)\n",
    "drrf.fit(Z, dr_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feat = np.argsort(drrf.feature_importances_)[-1]\n",
    "print(Z.columns[top_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.unique(np.percentile(Z.iloc[:, top_feat], np.arange(0, 105, 5)))\n",
    "Zpd = pd.DataFrame(np.tile(np.median(Z.values, axis=0, keepdims=True), (len(grid), 1)),\n",
    "                    columns=Z.columns)\n",
    "Zpd.iloc[:, top_feat] = grid\n",
    "\n",
    "preds, lb, ub = drrf.predict(Zpd, interval=True, alpha=.1)\n",
    "preds = preds.flatten()\n",
    "lb = lb.flatten()\n",
    "ub = ub.flatten()\n",
    "plt.errorbar(Zpd.iloc[:, top_feat], preds, yerr=(preds-lb, ub-preds))\n",
    "plt.xlabel(Zpd.columns[top_feat])\n",
    "plt.ylabel('Predicted CATE (at median value of other features)')\n",
    "plt.savefig(f'{data}-doubly-robust-forest.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_feats = Z.columns[np.argsort(drrf.feature_importances_)[::-1]]\n",
    "important_feats[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "for it, feature in enumerate(important_feats[:4]):\n",
    "    plt.subplot(2, 2, it + 1)\n",
    "    grid = np.unique(np.percentile(Z[feature], np.arange(0, 105, 5)))\n",
    "    Zpd = pd.DataFrame(np.tile(np.median(Z, axis=0, keepdims=True), (len(grid), 1)),\n",
    "                        columns=Z.columns)\n",
    "    Zpd[feature] = grid\n",
    "\n",
    "    preds, lb, ub = drrf.predict(Zpd, interval=True, alpha=.1)\n",
    "    preds = preds.flatten()\n",
    "    lb = lb.flatten()\n",
    "    ub = ub.flatten()\n",
    "    plt.errorbar(Zpd[feature], preds, yerr=(preds-lb, ub-preds))\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Predicted CATE')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{data}-drrf-marginal-plots.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if semi_synth:\n",
    "    true_proj = true_cate(X)\n",
    "    preds, lb, ub = drrf.predict(Z, interval=True, alpha=.1)\n",
    "    preds = preds.flatten()\n",
    "    lb = lb.flatten()\n",
    "    ub = ub.flatten()\n",
    "    inds = np.argsort(true_proj)\n",
    "    plt.plot(true_proj[inds], preds[inds])\n",
    "    plt.fill_between(true_proj[inds], lb[inds].flatten(), ub[inds].flatten(), alpha=.4)\n",
    "    plt.plot(np.linspace(np.min(true_proj), np.max(true_proj), 100),\n",
    "             np.linspace(np.min(true_proj), np.max(true_proj), 100))\n",
    "    plt.xlabel('True CATE')\n",
    "    plt.ylabel('Predicted CATE')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose our goal is to estimate the best treatment policy $\\pi: Z \\to \\{0, 1\\}$. The policy gains over no treatment for any policy $\\pi$ can be identified as:\n",
    "\\begin{align}\n",
    "V(\\pi) := E[\\pi(Z)\\, (Y(1) - Y(0))] = E\\left[\\pi(Z)\\, Y^{DR}(g,p)\\right]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating some personalized policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = (dr_preds - treatment_cost) * policy(Z)\n",
    "point = np.mean(pi)\n",
    "stderr = np.sqrt(np.var(pi) / pi.shape[0])\n",
    "print(f\"{point:.5f}, {stderr:.5f}, {point - 1.96 * stderr:.5f}, {point + 1.96 * stderr:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As compared to treating everyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = (dr_preds - treatment_cost)\n",
    "point = np.mean(pi)\n",
    "stderr = np.sqrt(np.var(pi) / pi.shape[0])\n",
    "print(f\"{point:.5f}, {stderr:.5f}, {point - 1.96 * stderr:.5f}, {point + 1.96 * stderr:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
