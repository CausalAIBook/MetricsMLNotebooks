{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"3.6.3"},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Analyzing RCT with Precision by Adjusting for Baseline Covariates"],"metadata":{"id":"w8J4Q7djd8zU"}},{"cell_type":"code","source":["install.packages(\"sandwich\")\n","install.packages(\"lmtest\")\n","library(sandwich) # heterokedasticity robust standard errors\n","library(lmtest) # coefficient testing"],"metadata":{"id":"VzLzwihLjfEJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Jonathan Roth's DGP\n","\n","Here we set up a DGP with heterogenous effects. In this example, which is due to Jonathan Roth, we have\n","$$\n","E [Y(0) | Z] = - Z, \\quad E [Y(1) |Z] = Z, \\quad Z \\sim N(0,1).\n","$$\n","The CATE is\n","$$\n","E [Y(1) - Y(0) | Z ]= 2 Z.\n","$$\n","and the ATE is\n","$$\n","2 E Z = 0.\n","$$\n","\n","We would like to estimate the ATE as precisely as possible.\n","\n","An economic motivation for this example could be provided as follows: Let D be the treatment of going to college, and let $Z$ be academic skills.  Suppose that academic skills cause lower earnings Y(0) in jobs that don't require a college degree, and cause higher earnings  Y(1) in jobs that do require college degrees. This type of scenario is reflected in the DGP set-up above.\n","\n"],"metadata":{"id":"XxvsV64Dd8zg"}},{"cell_type":"code","source":["# generate the simulated dataset\n","set.seed(123)        # set MC seed\n","n = 1000             # sample size\n","Z = rnorm(n)         # generate Z\n","Y0 = -Z + rnorm(n)   # conditional average baseline response is -Z\n","Y1 = Z + rnorm(n)    # conditional average treatment effect is +Z\n","D = (runif(n)<.2)    # treatment indicator; only 20% get treated\n","Y = Y1*D + Y0*(1-D)  # observed Y\n","D = D - mean(D)      # demean D\n","Z = Z-mean(Z)        # demean Z"],"metadata":{"execution":{"iopub.status.busy":"2021-07-13T19:12:27.196748Z","iopub.execute_input":"2021-07-13T19:12:27.199147Z","iopub.status.idle":"2021-07-13T19:12:27.227259Z"},"trusted":true,"id":"GXWON7gHd8zj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Analyze the RCT data with Precision Adjustment\n","\n","Consider the follow regression models:\n","\n","*  classical 2-sample approach, no adjustment (CL)\n","*  classical linear regression adjustment (CRA)\n","*  interactive regression adjusment (IRA)\n","\n","We carry out inference using heteroskedasticity robust inference, using the sandwich formulas for variance (Eicker-Huber-White).  \n","\n","We observe that the CRA delivers estimates that are less efficient than the CL (pointed out by Freedman), whereas the IRA delivers a more efficient approach (pointed out by Lin). In order for the CRA to be more efficient than the CL, we need the linear model to be a correct model of the conditional expectation function of Y given D and X, which is not the case here."],"metadata":{"id":"cdTsTrJxd8zr"}},{"cell_type":"code","source":["# implement each of the models on the simulated data\n","CL = lm(Y ~ D)\n","CRA = lm(Y ~ D+ Z)      #classical\n","IRA = lm(Y ~ D+ Z+ Z*D) #interactive approach\n","\n","# we are interested in the coefficients on variable \"D\".\n","coeftest(CL, vcov = vcovHC(CL, type=\"HC1\"))\n","coeftest(CRA, vcov = vcovHC(CRA, type=\"HC1\"))\n","coeftest(IRA, vcov = vcovHC(IRA, type=\"HC1\"))"],"metadata":{"execution":{"iopub.status.busy":"2021-07-13T19:12:27.229611Z","iopub.execute_input":"2021-07-13T19:12:27.231383Z","iopub.status.idle":"2021-07-13T19:12:27.283914Z"},"trusted":true,"id":"mGfqEgHLd8zs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Using classical standard errors (non-robust) is misleading here.\n","\n","We don't teach non-robust standard errors in econometrics courses, but the default statistical inference for lm() procedure in R, summary.lm(), still uses 100-year old concepts, perhaps in part due to historical legacy.  \n","\n","Here the non-robust standard errors suggest that there is not much difference between the different approaches, contrary to the conclusions reached using the robust standard errors.\n"],"metadata":{"id":"Fczm-t8ld8zu"}},{"cell_type":"code","source":["summary(CL)\n","summary(CRA)\n","summary(IRA)"],"metadata":{"execution":{"iopub.status.busy":"2021-07-13T19:12:27.286308Z","iopub.execute_input":"2021-07-13T19:12:27.288083Z","iopub.status.idle":"2021-07-13T19:12:27.31659Z"},"trusted":true,"id":"rOTRDgBld8zw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Verify Asymptotic Approximations Hold in Finite-Sample Simulation Experiment"],"metadata":{"id":"-6zymi0Md8z0"}},{"cell_type":"code","source":["set.seed(123)\n","n = 1000\n","B= 1000\n","\n","CLs = rep(0, B)\n","CRAs = rep(0, B)\n","IRAs = rep(0, B)\n","\n","for ( i in 1:B){\n","  Z = rnorm(n)\n","  Y0 = -Z + rnorm(n)\n","  Y1 =  Z + rnorm(n)\n","  Z = Z - mean(Z)\n","  D = (runif(n)<.1)\n","  D = D- mean(D)\n","  Y = Y1*D + Y0*(1-D)\n","  CLs[i]= lm(Y ~ D)$coef[2]\n","  CRAs[i] = lm(Y ~ D+ Z)$coef[2]\n","  IRAs[i] = lm(Y ~ D+ Z+ Z*D)$coef[2]\n","  }\n","\n","print(\"Standard deviations for estimators\")\n","\n","sqrt(mean(CLs^2))\n","sqrt(mean(CRAs^2))\n","sqrt(mean(IRAs^2))"],"metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","execution":{"iopub.status.busy":"2021-07-13T19:12:27.319053Z","iopub.execute_input":"2021-07-13T19:12:27.320929Z","iopub.status.idle":"2021-07-13T19:12:30.337708Z"},"trusted":true,"id":"bmtL0a9Nd8z2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NTFe4jwBlVNo"},"execution_count":null,"outputs":[]}]}